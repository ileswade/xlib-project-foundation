# Chapter 5: Media Manager - Design Detailed

> **ðŸŽ¥ DEEP DIVE INTO MEDIA PROCESSING ARCHITECTURE**
> Comprehensive exploration of xlibrary's Media Manager internals: watermarking algorithms, animation systems, timestamp processing, FFmpeg integration, and professional video workflows.

## Architecture Deep Dive

### Core Architecture Overview

The Media Manager employs a sophisticated architecture with specialized engines for different media operations:

```python
MediaManager
â”œâ”€â”€ WatermarkEngine        # Advanced watermarking with animations
â”œâ”€â”€ AnimationEngine       # Complex animation processing
â”œâ”€â”€ TimeStampParser       # Multi-format timestamp handling
â”œâ”€â”€ FFmpegProcessor      # Professional video processing
â””â”€â”€ ResolutionAdapter    # Intelligent scaling system

# Component initialization and orchestration
mm = MediaManager(config=ProcessingConfig())
mm.watermark_engine     # WatermarkEngine instance
mm.animation_engine     # AnimationEngine instance
mm.timestamp_parser     # TimeStampParser instance
mm.ffmpeg_processor     # FFmpegProcessor instance
```

### Watermarking System Architecture

#### Master Watermark Scaling Algorithm

The Media Manager uses a sophisticated master watermark approach that adapts to any target resolution:

```python
class ResolutionAdaptiveScaler:
    """
    Intelligent watermark scaling based on video resolution.
    Uses a single master watermark and scales appropriately.
    """

    # Resolution categories with optimization profiles
    RESOLUTION_PROFILES = {
        "240p": {
            "category": "mobile_low",
            "max_watermark_size": 48,
            "opacity_adjustment": -0.1,
            "margin_factor": 0.6,
            "compression": "high"
        },
        "360p": {
            "category": "mobile",
            "max_watermark_size": 64,
            "opacity_adjustment": -0.05,
            "margin_factor": 0.7,
            "compression": "medium"
        },
        "480p": {
            "category": "sd",
            "max_watermark_size": 96,
            "opacity_adjustment": 0,
            "margin_factor": 0.8,
            "compression": "medium"
        },
        "720p": {
            "category": "hd",
            "max_watermark_size": 128,
            "opacity_adjustment": 0,
            "margin_factor": 1.0,
            "compression": "low"
        },
        "1080p": {
            "category": "full_hd",
            "max_watermark_size": 192,
            "opacity_adjustment": 0,
            "margin_factor": 1.0,
            "compression": "low"
        },
        "1440p": {
            "category": "2k",
            "max_watermark_size": 256,
            "opacity_adjustment": 0.05,
            "margin_factor": 1.2,
            "compression": "none"
        },
        "4K": {
            "category": "4k",
            "max_watermark_size": 384,
            "opacity_adjustment": 0.1,
            "margin_factor": 1.5,
            "compression": "none"
        },
        "8K": {
            "category": "8k",
            "max_watermark_size": 512,
            "opacity_adjustment": 0.15,
            "margin_factor": 2.0,
            "compression": "none"
        }
    }

    def __init__(self):
        self.master_cache = {}  # Cache scaled versions
        self.quality_presets = self._initialize_quality_presets()

    def scale_watermark(self, master_watermark_path: Path,
                       target_resolution: Resolution,
                       watermark_config: WatermarkConfig) -> ScaledWatermark:
        """
        Scale master watermark to target resolution with quality optimization.
        """

        # Determine resolution category
        resolution_key = self._categorize_resolution(target_resolution)
        profile = self.RESOLUTION_PROFILES[resolution_key]

        # Calculate cache key for reuse
        cache_key = self._generate_cache_key(
            master_watermark_path, target_resolution, watermark_config
        )

        if cache_key in self.master_cache:
            return self.master_cache[cache_key]

        # Load and analyze master watermark
        master_image = self._load_master_watermark(master_watermark_path)
        master_analysis = self._analyze_watermark(master_image)

        # Calculate optimal scaled dimensions
        scaled_dimensions = self._calculate_scaled_dimensions(
            master_image.size,
            target_resolution,
            profile,
            watermark_config
        )

        # Perform high-quality scaling
        scaled_watermark = self._perform_scaling(
            master_image,
            scaled_dimensions,
            profile["compression"],
            master_analysis
        )

        # Apply resolution-specific optimizations
        optimized_watermark = self._apply_resolution_optimizations(
            scaled_watermark,
            profile,
            watermark_config
        )

        # Cache result
        result = ScaledWatermark(
            image=optimized_watermark,
            dimensions=scaled_dimensions,
            profile=profile,
            position_data=self._calculate_position(
                scaled_dimensions, target_resolution, watermark_config
            )
        )

        self.master_cache[cache_key] = result
        return result

    def _calculate_scaled_dimensions(self, master_size: Tuple[int, int],
                                   target_resolution: Resolution,
                                   profile: Dict,
                                   config: WatermarkConfig) -> Size:
        """Calculate optimal dimensions for scaled watermark."""

        master_width, master_height = master_size

        # Base scaling calculation
        if config.scale_by_percentage:
            # Scale by percentage of video dimensions
            max_width = target_resolution.width * config.max_width_percent
            max_height = target_resolution.height * config.max_height_percent
        else:
            # Use absolute size limits from profile
            max_width = profile["max_watermark_size"] * profile["margin_factor"]
            max_height = profile["max_watermark_size"] * profile["margin_factor"]

        # Maintain aspect ratio
        if config.maintain_aspect_ratio:
            scale_factor = min(max_width / master_width, max_height / master_height)
            scaled_width = int(master_width * scale_factor)
            scaled_height = int(master_height * scale_factor)
        else:
            scaled_width = int(max_width)
            scaled_height = int(max_height)

        # Apply user scale factor
        scaled_width = int(scaled_width * config.scale_factor)
        scaled_height = int(scaled_height * config.scale_factor)

        # Ensure minimum viable size
        scaled_width = max(scaled_width, 16)
        scaled_height = max(scaled_height, 16)

        return Size(scaled_width, scaled_height)

    def _perform_scaling(self, master_image, target_size: Size,
                        compression: str, analysis: Dict) -> Image:
        """Perform high-quality image scaling with content awareness."""

        # Choose resampling algorithm based on content and target size
        if analysis["has_fine_details"]:
            # Use Lanczos for detailed content
            resampling = Image.LANCZOS
        elif analysis["is_text_heavy"]:
            # Use nearest neighbor for crisp text at small sizes
            if target_size.width < 128:
                resampling = Image.NEAREST
            else:
                resampling = Image.LANCZOS
        else:
            # Use bicubic for general content
            resampling = Image.BICUBIC

        # Scale image
        scaled = master_image.resize(
            (target_size.width, target_size.height),
            resampling=resampling
        )

        # Apply sharpening if needed (for upscaling)
        if (target_size.width > master_image.width or
            target_size.height > master_image.height):
            scaled = self._apply_smart_sharpening(scaled, analysis)

        return scaled

    def _apply_resolution_optimizations(self, watermark: Image,
                                      profile: Dict,
                                      config: WatermarkConfig) -> Image:
        """Apply resolution-specific optimizations."""

        optimized = watermark.copy()

        # Adjust opacity based on resolution
        if profile["opacity_adjustment"] != 0:
            adjusted_opacity = max(0.1, min(1.0,
                config.opacity + profile["opacity_adjustment"]))

            # Apply opacity adjustment
            alpha = optimized.split()[-1]  # Get alpha channel
            alpha = ImageEnhance.Brightness(alpha).enhance(adjusted_opacity)
            optimized.putalpha(alpha)

        # Apply compression optimizations for lower resolutions
        if profile["compression"] == "high":
            # Reduce color depth for mobile/low-res displays
            optimized = self._optimize_for_mobile(optimized)
        elif profile["compression"] == "medium":
            # Light optimization
            optimized = self._light_optimize(optimized)

        return optimized
```

#### Advanced Position Calculation System

```python
class PositionCalculator:
    """Calculates precise watermark positions with advanced options."""

    def __init__(self):
        self.safe_area_margins = {
            "mobile": {"horizontal": 0.05, "vertical": 0.05},    # 5% margins
            "desktop": {"horizontal": 0.03, "vertical": 0.03},   # 3% margins
            "broadcast": {"horizontal": 0.1, "vertical": 0.1}    # 10% broadcast safe
        }

    def calculate_position(self, watermark_size: Size,
                         video_resolution: Resolution,
                         config: WatermarkConfig,
                         safe_area_mode: str = "desktop") -> Position:
        """Calculate watermark position with safe area considerations."""

        safe_margins = self.safe_area_margins[safe_area_mode]

        # Calculate safe area boundaries
        safe_left = int(video_resolution.width * safe_margins["horizontal"])
        safe_top = int(video_resolution.height * safe_margins["vertical"])
        safe_right = video_resolution.width - safe_left
        safe_bottom = video_resolution.height - safe_top

        # Base position calculation
        base_position = self._get_base_position(
            config.position, watermark_size, video_resolution
        )

        # Apply user offsets
        adjusted_x = base_position.x + config.offset_x
        adjusted_y = base_position.y + config.offset_y

        # Ensure position stays within safe area
        final_x = max(safe_left,
                     min(adjusted_x, safe_right - watermark_size.width))
        final_y = max(safe_top,
                     min(adjusted_y, safe_bottom - watermark_size.height))

        return Position(final_x, final_y)

    def _get_base_position(self, position: WatermarkPosition,
                          watermark_size: Size,
                          video_resolution: Resolution) -> Position:
        """Get base position before adjustments."""

        positions = {
            WatermarkPosition.TOP_LEFT: Position(0, 0),
            WatermarkPosition.TOP_CENTER: Position(
                (video_resolution.width - watermark_size.width) // 2, 0
            ),
            WatermarkPosition.TOP_RIGHT: Position(
                video_resolution.width - watermark_size.width, 0
            ),
            WatermarkPosition.CENTER_LEFT: Position(
                0, (video_resolution.height - watermark_size.height) // 2
            ),
            WatermarkPosition.CENTER: Position(
                (video_resolution.width - watermark_size.width) // 2,
                (video_resolution.height - watermark_size.height) // 2
            ),
            WatermarkPosition.CENTER_RIGHT: Position(
                video_resolution.width - watermark_size.width,
                (video_resolution.height - watermark_size.height) // 2
            ),
            WatermarkPosition.BOTTOM_LEFT: Position(
                0, video_resolution.height - watermark_size.height
            ),
            WatermarkPosition.BOTTOM_CENTER: Position(
                (video_resolution.width - watermark_size.width) // 2,
                video_resolution.height - watermark_size.height
            ),
            WatermarkPosition.BOTTOM_RIGHT: Position(
                video_resolution.width - watermark_size.width,
                video_resolution.height - watermark_size.height
            )
        }

        return positions[position]
```

### Animation System Architecture

#### Advanced Animation Engine

```python
class WatermarkAnimationEngine:
    """
    Sophisticated animation system for watermarks with timeline control.
    """

    def __init__(self):
        self.animation_cache = {}
        self.easing_functions = self._initialize_easing_functions()

    def create_animation(self, watermark: Image,
                        animation_type: WatermarkAnimation,
                        duration: float,
                        video_fps: float,
                        video_resolution: Resolution,
                        config: WatermarkConfig) -> AnimationSequence:
        """Create animation sequence for watermark."""

        total_frames = int(duration * video_fps)

        animation_generators = {
            WatermarkAnimation.FADE_IN: self._create_fade_in,
            WatermarkAnimation.FADE_OUT: self._create_fade_out,
            WatermarkAnimation.FADE_IN_OUT: self._create_fade_in_out,
            WatermarkAnimation.SCROLL_LEFT: self._create_scroll_left,
            WatermarkAnimation.SCROLL_RIGHT: self._create_scroll_right,
            WatermarkAnimation.SCROLL_UP: self._create_scroll_up,
            WatermarkAnimation.SCROLL_DOWN: self._create_scroll_down,
            WatermarkAnimation.CREDITS_ROLL: self._create_credits_roll,
            WatermarkAnimation.PULSE: self._create_pulse,
            WatermarkAnimation.BOUNCE: self._create_bounce
        }

        if animation_type not in animation_generators:
            raise WatermarkError(f"Unsupported animation type: {animation_type}")

        generator_func = animation_generators[animation_type]

        return generator_func(
            watermark=watermark,
            total_frames=total_frames,
            video_fps=video_fps,
            video_resolution=video_resolution,
            config=config
        )

    def _create_fade_in_out(self, watermark: Image, total_frames: int,
                           video_fps: float, video_resolution: Resolution,
                           config: WatermarkConfig) -> AnimationSequence:
        """Create sophisticated fade-in/fade-out animation."""

        # Calculate fade segments
        fade_in_frames = int(total_frames * 0.2)    # First 20%
        hold_frames = int(total_frames * 0.6)       # Middle 60%
        fade_out_frames = int(total_frames * 0.2)   # Last 20%

        frames = []

        # Fade in segment
        for i in range(fade_in_frames):
            progress = i / fade_in_frames
            # Use easing function for smooth animation
            eased_progress = self.easing_functions["ease_in_out"](progress)
            opacity = config.opacity * eased_progress

            frame = self._apply_opacity_animation(watermark, opacity)
            frames.append(AnimationFrame(
                image=frame,
                timestamp=i / video_fps,
                opacity=opacity,
                position=self._calculate_frame_position(i, config)
            ))

        # Hold segment (full opacity)
        for i in range(hold_frames):
            frame_index = fade_in_frames + i
            frame = self._apply_opacity_animation(watermark, config.opacity)
            frames.append(AnimationFrame(
                image=frame,
                timestamp=frame_index / video_fps,
                opacity=config.opacity,
                position=self._calculate_frame_position(frame_index, config)
            ))

        # Fade out segment
        for i in range(fade_out_frames):
            frame_index = fade_in_frames + hold_frames + i
            progress = i / fade_out_frames
            eased_progress = self.easing_functions["ease_in_out"](progress)
            opacity = config.opacity * (1.0 - eased_progress)

            frame = self._apply_opacity_animation(watermark, opacity)
            frames.append(AnimationFrame(
                image=frame,
                timestamp=frame_index / video_fps,
                opacity=opacity,
                position=self._calculate_frame_position(frame_index, config)
            ))

        return AnimationSequence(
            frames=frames,
            duration=total_frames / video_fps,
            animation_type=WatermarkAnimation.FADE_IN_OUT
        )

    def _create_scroll_left(self, watermark: Image, total_frames: int,
                           video_fps: float, video_resolution: Resolution,
                           config: WatermarkConfig) -> AnimationSequence:
        """Create left-scrolling animation with smooth motion."""

        frames = []
        start_x = video_resolution.width  # Start off-screen right
        end_x = -watermark.width          # End off-screen left
        total_distance = start_x - end_x

        for i in range(total_frames):
            progress = i / total_frames
            # Use smooth easing for natural motion
            eased_progress = self.easing_functions["linear"](progress)

            current_x = start_x - (total_distance * eased_progress)
            current_y = self._get_base_y_position(config.position, watermark.height,
                                                 video_resolution.height)

            # Apply position offsets
            current_x += config.offset_x
            current_y += config.offset_y

            frame = watermark.copy()
            frames.append(AnimationFrame(
                image=frame,
                timestamp=i / video_fps,
                opacity=config.opacity,
                position=Position(int(current_x), int(current_y))
            ))

        return AnimationSequence(
            frames=frames,
            duration=total_frames / video_fps,
            animation_type=WatermarkAnimation.SCROLL_LEFT
        )

    def _create_pulse(self, watermark: Image, total_frames: int,
                     video_fps: float, video_resolution: Resolution,
                     config: WatermarkConfig) -> AnimationSequence:
        """Create pulsing animation with scale and opacity changes."""

        frames = []
        base_position = self._calculate_base_position(watermark, video_resolution, config)

        # Pulse parameters
        pulse_frequency = 1.0  # 1 pulse per second
        pulse_amplitude = 0.2  # 20% scale variation
        opacity_variation = 0.3  # 30% opacity variation

        for i in range(total_frames):
            timestamp = i / video_fps

            # Calculate pulse phase (0 to 2Ï€)
            phase = (timestamp * pulse_frequency * 2 * math.pi) % (2 * math.pi)

            # Calculate scale factor (1.0 Â± pulse_amplitude)
            scale_factor = 1.0 + (math.sin(phase) * pulse_amplitude)

            # Calculate opacity (base_opacity Â± opacity_variation)
            opacity_factor = 1.0 + (math.sin(phase) * opacity_variation)
            current_opacity = config.opacity * max(0.1, opacity_factor)

            # Scale watermark
            scaled_size = (
                int(watermark.width * scale_factor),
                int(watermark.height * scale_factor)
            )
            scaled_watermark = watermark.resize(scaled_size, Image.LANCZOS)

            # Apply opacity
            pulsed_frame = self._apply_opacity_animation(scaled_watermark, current_opacity)

            # Adjust position for centered scaling
            position_offset_x = (watermark.width - scaled_size[0]) // 2
            position_offset_y = (watermark.height - scaled_size[1]) // 2

            frames.append(AnimationFrame(
                image=pulsed_frame,
                timestamp=timestamp,
                opacity=current_opacity,
                position=Position(
                    base_position.x + position_offset_x,
                    base_position.y + position_offset_y
                )
            ))

        return AnimationSequence(
            frames=frames,
            duration=total_frames / video_fps,
            animation_type=WatermarkAnimation.PULSE
        )

    def _initialize_easing_functions(self) -> Dict[str, Callable]:
        """Initialize easing functions for smooth animations."""
        return {
            "linear": lambda t: t,
            "ease_in": lambda t: t * t,
            "ease_out": lambda t: 1 - (1 - t) ** 2,
            "ease_in_out": lambda t: 2 * t * t if t < 0.5 else -1 + (4 - 2 * t) * t,
            "ease_in_cubic": lambda t: t ** 3,
            "ease_out_cubic": lambda t: 1 - (1 - t) ** 3,
            "bounce": lambda t: self._bounce_easing(t),
            "elastic": lambda t: self._elastic_easing(t)
        }

    def _bounce_easing(self, t: float) -> float:
        """Bounce easing function."""
        if t < 1/2.75:
            return 7.5625 * t * t
        elif t < 2/2.75:
            return 7.5625 * (t - 1.5/2.75) * (t - 1.5/2.75) + 0.75
        elif t < 2.5/2.75:
            return 7.5625 * (t - 2.25/2.75) * (t - 2.25/2.75) + 0.9375
        else:
            return 7.5625 * (t - 2.625/2.75) * (t - 2.625/2.75) + 0.984375
```

### Timestamp Processing System

#### Advanced Timestamp Parser

```python
class TimeStampParser:
    """
    Advanced timestamp parsing with support for multiple formats,
    frame-accurate positioning, and automatic format detection.
    """

    def __init__(self):
        self.format_patterns = self._initialize_patterns()
        self.validation_rules = self._initialize_validation()
        self.conversion_cache = {}

    def _initialize_patterns(self) -> Dict[str, Dict]:
        """Initialize timestamp format patterns and parsers."""
        return {
            "hours_minutes_seconds": {
                "pattern": r"^(\d{1,2}):(\d{1,2}):(\d{1,2})(?:\.(\d+))?$",
                "example": "01:23:45.678",
                "parser": self._parse_hms
            },
            "minutes_seconds": {
                "pattern": r"^(\d{1,2}):(\d{1,2})(?:\.(\d+))?$",
                "example": "23:45.678",
                "parser": self._parse_ms
            },
            "frame_number": {
                "pattern": r"^f(\d+)$",
                "example": "f1500",
                "parser": self._parse_frame
            },
            "seconds_decimal": {
                "pattern": r"^(\d+(?:\.\d+)?)s?$",
                "example": "123.456" or "123.456s",
                "parser": self._parse_seconds
            },
            "timecode_smpte": {
                "pattern": r"^(\d{2}):(\d{2}):(\d{2}):(\d{2})$",
                "example": "01:23:45:12",
                "parser": self._parse_smpte
            },
            "milliseconds": {
                "pattern": r"^(\d+)ms$",
                "example": "123456ms",
                "parser": self._parse_milliseconds
            }
        }

    def parse(self, timestamp_str: str,
             video_fps: float = 30.0,
             video_duration: Optional[float] = None) -> TimeStamp:
        """
        Parse timestamp string with automatic format detection.

        Args:
            timestamp_str: The timestamp string to parse
            video_fps: Video frame rate for frame calculations
            video_duration: Video duration for validation (optional)

        Returns:
            TimeStamp object with frame and seconds information
        """

        # Check cache first
        cache_key = (timestamp_str, video_fps)
        if cache_key in self.conversion_cache:
            return self.conversion_cache[cache_key]

        # Try each format pattern
        for format_name, format_info in self.format_patterns.items():
            pattern = format_info["pattern"]
            parser = format_info["parser"]

            match = re.match(pattern, timestamp_str.strip())
            if match:
                try:
                    timestamp = parser(match, video_fps)

                    # Validate timestamp
                    if video_duration:
                        self._validate_timestamp(timestamp, video_duration)

                    # Cache result
                    self.conversion_cache[cache_key] = timestamp
                    return timestamp

                except (ValueError, TimestampError) as e:
                    continue  # Try next format

        # If no format matched, raise error with helpful message
        formats_list = [f"{info['example']}" for info in self.format_patterns.values()]
        raise TimestampError(
            f"Unsupported timestamp format: '{timestamp_str}'. "
            f"Supported formats: {', '.join(formats_list)}"
        )

    def _parse_hms(self, match: re.Match, video_fps: float) -> TimeStamp:
        """Parse HH:MM:SS.mmm format."""
        hours = int(match.group(1))
        minutes = int(match.group(2))
        seconds = int(match.group(3))
        milliseconds = int(match.group(4) or 0)

        # Validate ranges
        if minutes >= 60 or seconds >= 60:
            raise TimestampError("Invalid minutes or seconds value")
        if milliseconds >= 1000:
            raise TimestampError("Invalid milliseconds value")

        total_seconds = hours * 3600 + minutes * 60 + seconds + milliseconds / 1000
        frame_number = int(total_seconds * video_fps)

        return TimeStamp(
            frame=frame_number,
            seconds=total_seconds,
            fps=video_fps,
            format_detected="hours_minutes_seconds"
        )

    def _parse_frame(self, match: re.Match, video_fps: float) -> TimeStamp:
        """Parse frame number format (f1234)."""
        frame_number = int(match.group(1))

        if frame_number < 0:
            raise TimestampError("Frame number cannot be negative")

        seconds = frame_number / video_fps

        return TimeStamp(
            frame=frame_number,
            seconds=seconds,
            fps=video_fps,
            format_detected="frame_number"
        )

    def _parse_smpte(self, match: re.Match, video_fps: float) -> TimeStamp:
        """Parse SMPTE timecode format (HH:MM:SS:FF)."""
        hours = int(match.group(1))
        minutes = int(match.group(2))
        seconds = int(match.group(3))
        frames = int(match.group(4))

        # Validate SMPTE format
        if minutes >= 60 or seconds >= 60 or frames >= video_fps:
            raise TimestampError("Invalid SMPTE timecode values")

        total_frames = int(hours * 3600 * video_fps +
                          minutes * 60 * video_fps +
                          seconds * video_fps + frames)

        total_seconds = total_frames / video_fps

        return TimeStamp(
            frame=total_frames,
            seconds=total_seconds,
            fps=video_fps,
            format_detected="timecode_smpte"
        )

    def convert_timestamp(self, timestamp: TimeStamp,
                         target_format: str,
                         target_fps: Optional[float] = None) -> str:
        """Convert timestamp to specified format."""

        # Use original fps if target_fps not specified
        fps = target_fps or timestamp.fps

        # Recalculate for different fps if needed
        if target_fps and target_fps != timestamp.fps:
            # Convert via seconds for fps conversion
            new_frame = int(timestamp.seconds * target_fps)
            working_timestamp = TimeStamp(new_frame, timestamp.seconds, target_fps)
        else:
            working_timestamp = timestamp

        converters = {
            "hms": self._to_hms_format,
            "ms": self._to_ms_format,
            "frame": self._to_frame_format,
            "seconds": self._to_seconds_format,
            "smpte": self._to_smpte_format,
            "milliseconds": self._to_milliseconds_format
        }

        if target_format not in converters:
            raise TimestampError(f"Unsupported output format: {target_format}")

        return converters[target_format](working_timestamp)

    def _to_hms_format(self, timestamp: TimeStamp) -> str:
        """Convert to HH:MM:SS.mmm format."""
        total_seconds = timestamp.seconds
        hours = int(total_seconds // 3600)
        minutes = int((total_seconds % 3600) // 60)
        seconds = int(total_seconds % 60)
        milliseconds = int((total_seconds % 1) * 1000)

        return f"{hours:02d}:{minutes:02d}:{seconds:02d}.{milliseconds:03d}"

    def _to_smpte_format(self, timestamp: TimeStamp) -> str:
        """Convert to SMPTE timecode format (HH:MM:SS:FF)."""
        total_frames = timestamp.frame
        fps = timestamp.fps

        hours = int(total_frames // (3600 * fps))
        remaining_frames = total_frames % (3600 * fps)

        minutes = int(remaining_frames // (60 * fps))
        remaining_frames = remaining_frames % (60 * fps)

        seconds = int(remaining_frames // fps)
        frames = int(remaining_frames % fps)

        return f"{hours:02d}:{minutes:02d}:{seconds:02d}:{frames:02d}"
```

### FFmpeg Integration Architecture

#### Professional Video Processing Pipeline

```python
class FFmpegProcessor:
    """
    Professional video processing with comprehensive FFmpeg integration.
    Handles complex operations like precise trimming, watermarking, and format conversion.
    """

    def __init__(self, config: ProcessingConfig):
        self.config = config
        self.ffmpeg_path = self._locate_ffmpeg()
        self.ffprobe_path = self._locate_ffprobe()
        self.hardware_acceleration = self._detect_hardware_acceleration()
        self.processing_queue = []

    def _locate_ffmpeg(self) -> Path:
        """Locate FFmpeg executable with comprehensive search."""
        search_paths = [
            # Common installation paths
            "/usr/local/bin/ffmpeg",
            "/opt/homebrew/bin/ffmpeg",
            "/usr/bin/ffmpeg",

            # Windows paths
            "C:\\Program Files\\ffmpeg\\bin\\ffmpeg.exe",
            "C:\\ffmpeg\\bin\\ffmpeg.exe",

            # Check PATH
            shutil.which("ffmpeg")
        ]

        for path in search_paths:
            if path and Path(path).exists():
                return Path(path)

        raise FFmpegNotFoundError(
            "FFmpeg not found. Install with: brew install ffmpeg (macOS) or "
            "download from https://ffmpeg.org/"
        )

    def trim_video_precise(self, input_path: Path,
                          start_timestamp: TimeStamp,
                          end_timestamp: TimeStamp,
                          output_path: Path) -> ProcessingResult:
        """
        Frame-accurate video trimming with professional quality preservation.
        """

        # Build FFmpeg command for precise trimming
        cmd = [
            str(self.ffmpeg_path),
            "-i", str(input_path),

            # Precise seeking
            "-ss", str(start_timestamp.seconds),
            "-to", str(end_timestamp.seconds),

            # Quality preservation
            "-c", "copy",                        # Stream copy when possible
            "-avoid_negative_ts", "make_zero",   # Handle timestamp issues

            # Metadata preservation
            "-map_metadata", "0",                # Copy all metadata

            # Professional settings
            "-movflags", "+faststart",           # Web-optimized MP4

            # Output options
            "-y",                                # Overwrite existing
            str(output_path)
        ]

        # Add hardware acceleration if available
        if self.hardware_acceleration:
            cmd.extend(self._get_hardware_acceleration_flags())

        return self._execute_ffmpeg_command(cmd, "trim_video_precise")

    def apply_watermark_advanced(self, video_path: Path,
                                watermark_sequence: AnimationSequence,
                                output_path: Path) -> ProcessingResult:
        """
        Apply advanced watermark with animation support.
        """

        # Create temporary directory for animation frames
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)

            # Export animation frames
            frame_paths = self._export_animation_frames(
                watermark_sequence, temp_path
            )

            # Build complex FFmpeg filter graph
            filter_complex = self._build_watermark_filter_graph(
                watermark_sequence, frame_paths
            )

            cmd = [
                str(self.ffmpeg_path),
                "-i", str(video_path),

                # Add watermark frame inputs
                *self._get_watermark_inputs(frame_paths),

                # Complex filter graph
                "-filter_complex", filter_complex,

                # Audio handling
                "-c:a", "copy",                  # Copy audio without re-encoding

                # Video encoding
                "-c:v", self.config.video_codec,
                "-crf", str(self.config.quality_crf),

                # Output
                "-y",
                str(output_path)
            ]

            return self._execute_ffmpeg_command(cmd, "apply_watermark_advanced")

    def _build_watermark_filter_graph(self, sequence: AnimationSequence,
                                     frame_paths: List[Path]) -> str:
        """Build complex FFmpeg filter graph for animated watermarks."""

        if sequence.animation_type == WatermarkAnimation.STATIC:
            # Simple static overlay
            return f"[0:v][1:v]overlay={sequence.frames[0].position.x}:{sequence.frames[0].position.y}"

        elif sequence.animation_type == WatermarkAnimation.FADE_IN_OUT:
            # Complex fade animation with timeline
            filters = []

            for i, frame in enumerate(sequence.frames):
                start_time = frame.timestamp
                end_time = start_time + (1.0 / sequence.fps) if i < len(sequence.frames) - 1 else sequence.duration

                overlay_filter = (
                    f"[0:v][{i+1}:v]overlay="
                    f"{frame.position.x}:{frame.position.y}:"
                    f"enable='between(t,{start_time},{end_time})':"
                    f"eval=frame"
                )
                filters.append(overlay_filter)

            return "; ".join(filters)

        # Add more animation types...
        return self._build_generic_animation_filter(sequence)

    def analyze_video_comprehensive(self, video_path: Path) -> VideoAnalysis:
        """Comprehensive video analysis using ffprobe."""

        cmd = [
            str(self.ffprobe_path),
            "-v", "quiet",
            "-print_format", "json",
            "-show_format",
            "-show_streams",
            "-show_chapters",
            str(video_path)
        ]

        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=30
            )

            if result.returncode != 0:
                raise ProcessingError(f"Video analysis failed: {result.stderr}")

            analysis_data = json.loads(result.stdout)
            return self._parse_video_analysis(analysis_data)

        except subprocess.TimeoutExpired:
            raise ProcessingError("Video analysis timed out")
        except json.JSONDecodeError:
            raise ProcessingError("Invalid ffprobe output")

    def _parse_video_analysis(self, data: Dict) -> VideoAnalysis:
        """Parse ffprobe output into structured analysis."""

        format_info = data.get("format", {})
        streams = data.get("streams", [])

        # Find video stream
        video_stream = None
        audio_streams = []

        for stream in streams:
            if stream.get("codec_type") == "video":
                video_stream = stream
            elif stream.get("codec_type") == "audio":
                audio_streams.append(stream)

        if not video_stream:
            raise ProcessingError("No video stream found")

        # Extract video metadata
        video_metadata = VideoMetadata(
            duration=float(format_info.get("duration", 0)),
            fps=eval(video_stream.get("r_frame_rate", "30/1")),  # Handle fractional fps
            resolution=Resolution(
                width=int(video_stream.get("width", 0)),
                height=int(video_stream.get("height", 0))
            ),
            codec=video_stream.get("codec_name", "unknown"),
            bitrate=int(format_info.get("bit_rate", 0)),
            has_audio=len(audio_streams) > 0,
            audio_codec=audio_streams[0].get("codec_name") if audio_streams else None,
            file_size=int(format_info.get("size", 0)),
            format_name=format_info.get("format_name", "unknown")
        )

        return VideoAnalysis(
            metadata=video_metadata,
            streams=streams,
            format_info=format_info,
            processing_recommendations=self._generate_processing_recommendations(video_metadata)
        )

    def _generate_processing_recommendations(self, metadata: VideoMetadata) -> Dict[str, Any]:
        """Generate intelligent processing recommendations based on video analysis."""

        recommendations = {
            "optimal_codec": "h264",
            "optimal_crf": 23,
            "hardware_acceleration": False,
            "watermark_scaling": "auto",
            "quality_preset": "medium"
        }

        # Resolution-based recommendations
        if metadata.resolution.width >= 3840:  # 4K+
            recommendations.update({
                "optimal_crf": 26,
                "hardware_acceleration": True,
                "quality_preset": "slow",
                "watermark_scaling": "4k"
            })
        elif metadata.resolution.width >= 1920:  # 1080p
            recommendations.update({
                "optimal_crf": 23,
                "quality_preset": "medium",
                "watermark_scaling": "1080p"
            })
        elif metadata.resolution.width <= 720:  # HD and below
            recommendations.update({
                "optimal_crf": 20,
                "quality_preset": "fast",
                "watermark_scaling": "720p"
            })

        # Bitrate-based recommendations
        if metadata.bitrate > 50000000:  # > 50 Mbps (high bitrate)
            recommendations["quality_preset"] = "slow"
        elif metadata.bitrate < 5000000:  # < 5 Mbps (low bitrate)
            recommendations["quality_preset"] = "fast"

        return recommendations
```

This detailed architecture documentation provides the foundation for understanding xlibrary's sophisticated media processing capabilities, from intelligent watermarking to professional video workflows.

---

## Next Steps

- **[User Guide Overview](05.03%20Chapter%205%20-%20Media%20Manager%20-%20User%20Guide%20-%20Overview.md)** - Quick start guide for media processing
- **[User Guide Detailed](05.04%20Chapter%205%20-%20Media%20Manager%20-%20User%20Guide%20-%20Detailed.md)** - Comprehensive media workflows and examples
- **[Chapter 6: Communication Manager](06.01%20Chapter%206%20-%20Communication%20Manager%20-%20Design%20-%20Overview.md)** - Email and messaging systems

**Deep understanding of Media Manager architecture enables professional-grade video and image processing.** ðŸŽ¥