# Chapter 2: Config Manager - Detailed Design Discussion

> **üèóÔ∏è DEEP ARCHITECTURAL ANALYSIS**
> Comprehensive exploration of Config Manager's internal architecture, TOML processing, schema validation system, encryption mechanisms, and engineering decisions.

## Table of Contents

- [Core Architecture](#core-architecture)
- [TOML Processing System](#toml-processing-system)
- [Schema Validation Engine](#schema-validation-engine)
- [Interpolation System](#interpolation-system)
- [Encryption Architecture](#encryption-architecture)
- [Hierarchical Configuration](#hierarchical-configuration)
- [Auto-Reload Mechanism](#auto-reload-mechanism)
- [Error Handling Architecture](#error-handling-architecture)
- [Performance Engineering](#performance-engineering)
- [Extensibility Patterns](#extensibility-patterns)

---

## Core Architecture

### Component Overview

The Config Manager follows a layered architecture with clear separation of concerns:

```
ConfigManager (Public Interface)
‚îú‚îÄ‚îÄ Configuration Loading Layer
‚îÇ   ‚îú‚îÄ‚îÄ Source Resolution (File/Path handling)
‚îÇ   ‚îú‚îÄ‚îÄ Loader System (TOML, JSON, YAML)
‚îÇ   ‚îú‚îÄ‚îÄ Hierarchical Merging
‚îÇ   ‚îî‚îÄ‚îÄ Environment Selection
‚îú‚îÄ‚îÄ Processing Layer
‚îÇ   ‚îú‚îÄ‚îÄ Schema Validation Engine
‚îÇ   ‚îú‚îÄ‚îÄ Interpolation Engine
‚îÇ   ‚îú‚îÄ‚îÄ Type Coercion System
‚îÇ   ‚îî‚îÄ‚îÄ Value Resolution
‚îú‚îÄ‚îÄ Security Layer
‚îÇ   ‚îú‚îÄ‚îÄ Encryption/Decryption
‚îÇ   ‚îú‚îÄ‚îÄ Sensitive Value Detection
‚îÇ   ‚îú‚îÄ‚îÄ Key Management
‚îÇ   ‚îî‚îÄ‚îÄ Secure Storage
‚îú‚îÄ‚îÄ Access Layer
‚îÇ   ‚îú‚îÄ‚îÄ Dot-notation Access
‚îÇ   ‚îú‚îÄ‚îÄ Type-safe Getters
‚îÇ   ‚îú‚îÄ‚îÄ Default Value Handling
‚îÇ   ‚îî‚îÄ‚îÄ Caching System
‚îî‚îÄ‚îÄ Monitoring Layer
    ‚îú‚îÄ‚îÄ File Change Detection
    ‚îú‚îÄ‚îÄ Auto-reload Triggers
    ‚îú‚îÄ‚îÄ Configuration Validation
    ‚îî‚îÄ‚îÄ Error Reporting
```

### Design Patterns Used

#### 1. **Strategy Pattern**
Pluggable configuration loaders:

```python
class ConfigLoader(ABC):
    """Abstract base for configuration loaders"""

    @abstractmethod
    def can_load(self, source: Union[str, Path]) -> bool:
        """Check if this loader can handle the source"""
        pass

    @abstractmethod
    def load(self, source: Union[str, Path]) -> LoadResult:
        """Load configuration from source"""
        pass

class TomlLoader(ConfigLoader):
    """TOML configuration loader"""

    def can_load(self, source: Union[str, Path]) -> bool:
        return str(source).endswith(('.toml', '.tml'))

    def load(self, source: Union[str, Path]) -> LoadResult:
        # TOML-specific loading logic
        pass
```

#### 2. **Template Method Pattern**
Configuration processing pipeline:

```python
class ConfigManager:
    def _load_configuration(self) -> Dict[str, Any]:
        """Template method for configuration loading"""
        sources = self._resolve_sources()
        raw_data = self._load_from_sources(sources)
        merged_data = self._merge_configurations(raw_data)
        interpolated_data = self._apply_interpolation(merged_data)
        validated_data = self._validate_configuration(interpolated_data)
        return validated_data
```

#### 3. **Observer Pattern**
File change monitoring and auto-reload:

```python
class ConfigurationWatcher:
    """Watches configuration files for changes"""

    def __init__(self, config_manager: ConfigManager):
        self.config_manager = config_manager
        self.observers = []

    def add_observer(self, callback):
        self.observers.append(callback)

    def notify_change(self, changed_files):
        for observer in self.observers:
            observer(changed_files)
```

#### 4. **Builder Pattern**
Schema construction with fluent interface:

```python
schema = Schema.builder() \
    .add_section("database") \
        .add_field("host", required(str)) \
        .add_field("port", required(int) | range_check(1, 65535)) \
        .add_field("timeout", optional(float, default=30.0)) \
    .add_section("api") \
        .add_field("key", required(str) | pattern(r"^[a-zA-Z0-9_-]+$")) \
    .build()
```

---

## TOML Processing System

### TOML Parser Architecture

The Config Manager uses a sophisticated TOML processing system:

```python
class AdvancedTomlLoader(ConfigLoader):
    """Advanced TOML loader with xlibrary extensions"""

    def __init__(self):
        self._toml_parser = self._create_parser()
        self._extensions = {
            'include': self._handle_include,
            'inherit': self._handle_inheritance,
            'template': self._handle_templating
        }

    def load(self, source: Union[str, Path]) -> LoadResult:
        """Load TOML with advanced features"""
        try:
            # Read raw content
            content = self._read_file(source)

            # Process xlibrary extensions
            processed_content = self._process_extensions(content)

            # Parse TOML
            parsed_data = self._toml_parser.loads(processed_content)

            # Post-process parsed data
            processed_data = self._post_process(parsed_data)

            return LoadResult(
                data=processed_data,
                source=source,
                timestamp=time.time(),
                metadata=self._extract_metadata(parsed_data)
            )

        except Exception as e:
            raise ConfigError(f"Failed to load TOML from {source}: {e}")
```

### TOML Extension Support

Custom TOML extensions for advanced functionality:

#### Include System
```toml
# base.toml
[database]
host = "localhost"
port = 5432

# Include other configuration files
[include]
files = ["database.toml", "api.toml"]
```

#### Template Variables
```toml
# Template definitions
[templates]
database_url = "postgresql://${host}:${port}/${name}"

# Usage with substitution
[database]
host = "prod-server"
port = 5432
name = "myapp"
url = "${templates.database_url}"  # Resolves to full URL
```

#### Conditional Sections
```toml
# Environment-specific configuration
[development]
debug = true
log_level = "DEBUG"

[production]
debug = false
log_level = "INFO"

# Current environment selection
[config]
environment = "development"  # or from ENV var
```

### Advanced TOML Features

#### Multi-line String Support
```toml
[logging]
format = """
[${timestamp}] ${level}: ${message}
Context: ${context}
File: ${file}:${line}
"""

[database]
query = '''
SELECT users.name, users.email, profiles.bio
FROM users
JOIN profiles ON users.id = profiles.user_id
WHERE users.active = true
'''
```

#### Array of Tables with Validation
```toml
# Multiple database connections
[[databases]]
name = "primary"
host = "db1.example.com"
port = 5432
read_only = false

[[databases]]
name = "replica"
host = "db2.example.com"
port = 5432
read_only = true
```

---

## Schema Validation Engine

### Validation System Architecture

Comprehensive validation system with composable validators:

```python
class Schema:
    """Configuration schema with validation rules"""

    def __init__(self, schema_definition: Dict[str, Any]):
        self.definition = schema_definition
        self.validators = self._compile_validators(schema_definition)
        self.metadata = {}

    def validate(self, data: Dict[str, Any]) -> ValidationResult:
        """Validate configuration data against schema"""
        errors = []
        warnings = []

        try:
            # Structure validation
            structure_errors = self._validate_structure(data)
            errors.extend(structure_errors)

            # Type validation
            type_errors = self._validate_types(data)
            errors.extend(type_errors)

            # Constraint validation
            constraint_errors = self._validate_constraints(data)
            errors.extend(constraint_errors)

            # Cross-field validation
            cross_field_errors = self._validate_cross_fields(data)
            errors.extend(cross_field_errors)

            return ValidationResult(
                is_valid=len(errors) == 0,
                errors=errors,
                warnings=warnings,
                validated_data=data if len(errors) == 0 else None
            )

        except Exception as e:
            return ValidationResult(
                is_valid=False,
                errors=[ValidationError(f"Schema validation failed: {e}")],
                warnings=[],
                validated_data=None
            )
```

### Validator Types

#### Basic Type Validators
```python
class TypeValidator:
    """Validates value types with coercion support"""

    def __init__(self, expected_type: Type, coerce: bool = True):
        self.expected_type = expected_type
        self.coerce = coerce
        self.coercion_functions = {
            int: self._coerce_int,
            float: self._coerce_float,
            bool: self._coerce_bool,
            str: self._coerce_str
        }

    def validate(self, value: Any, path: str = "") -> ValidationResult:
        """Validate and optionally coerce value type"""
        if isinstance(value, self.expected_type):
            return ValidationResult.success(value)

        if self.coerce and self.expected_type in self.coercion_functions:
            try:
                coerced_value = self.coercion_functions[self.expected_type](value)
                return ValidationResult.success(coerced_value)
            except (ValueError, TypeError) as e:
                pass

        return ValidationResult.error(
            f"Expected {self.expected_type.__name__} at '{path}', got {type(value).__name__}",
            suggestion=f"Convert '{value}' to {self.expected_type.__name__}"
        )
```

#### Constraint Validators
```python
class RangeValidator:
    """Validates numeric ranges"""

    def __init__(self, min_val: Optional[float] = None, max_val: Optional[float] = None):
        self.min_val = min_val
        self.max_val = max_val

    def validate(self, value: Union[int, float], path: str = "") -> ValidationResult:
        if not isinstance(value, (int, float)):
            return ValidationResult.error(f"Range validation requires numeric value at '{path}'")

        if self.min_val is not None and value < self.min_val:
            return ValidationResult.error(
                f"Value {value} at '{path}' is below minimum {self.min_val}",
                suggestion=f"Use a value >= {self.min_val}"
            )

        if self.max_val is not None and value > self.max_val:
            return ValidationResult.error(
                f"Value {value} at '{path}' is above maximum {self.max_val}",
                suggestion=f"Use a value <= {self.max_val}"
            )

        return ValidationResult.success(value)

class PatternValidator:
    """Validates string patterns using regex"""

    def __init__(self, pattern: str, flags: int = 0):
        self.pattern = re.compile(pattern, flags)
        self.pattern_str = pattern

    def validate(self, value: str, path: str = "") -> ValidationResult:
        if not isinstance(value, str):
            return ValidationResult.error(f"Pattern validation requires string value at '{path}'")

        if not self.pattern.match(value):
            return ValidationResult.error(
                f"Value '{value}' at '{path}' does not match pattern '{self.pattern_str}'",
                suggestion=f"Ensure value matches the required format: {self.pattern_str}"
            )

        return ValidationResult.success(value)
```

#### Composite Validators
```python
class CompositeValidator:
    """Combines multiple validators with logical operators"""

    def __init__(self, validators: List[Validator], operator: str = "and"):
        self.validators = validators
        self.operator = operator  # "and", "or", "xor"

    def validate(self, value: Any, path: str = "") -> ValidationResult:
        results = [validator.validate(value, path) for validator in self.validators]

        if self.operator == "and":
            # All validators must pass
            errors = []
            for result in results:
                if not result.is_valid:
                    errors.extend(result.errors)

            return ValidationResult(
                is_valid=len(errors) == 0,
                errors=errors,
                validated_data=value if len(errors) == 0 else None
            )

        elif self.operator == "or":
            # At least one validator must pass
            for result in results:
                if result.is_valid:
                    return result

            # All failed
            all_errors = []
            for result in results:
                all_errors.extend(result.errors)

            return ValidationResult(
                is_valid=False,
                errors=[ValidationError(f"None of the alternative validations passed for '{path}'")],
                details=all_errors
            )
```

### Schema DSL (Domain Specific Language)

Fluent schema definition interface:

```python
# Fluent schema definition
schema = Schema({
    "database": {
        "host": required(str) | pattern(r"^[a-zA-Z0-9.-]+$"),
        "port": required(int) | range_check(1, 65535),
        "timeout": optional(float, default=30.0) | range_check(0.1, 300.0),
        "ssl_enabled": optional(bool, default=True),
        "connection_pool": {
            "min_size": required(int) | range_check(1, 100),
            "max_size": required(int) | range_check(1, 1000),
            # Cross-field validation
            "_constraints": [
                lambda data: data["max_size"] >= data["min_size"]
            ]
        }
    },
    "api": {
        "endpoints": {
            "*": {  # Wildcard for dynamic keys
                "url": required(str) | pattern(r"^https?://"),
                "timeout": optional(float, default=30.0),
                "retries": optional(int, default=3) | range_check(0, 10)
            }
        }
    }
})
```

---

## Interpolation System

### Variable Resolution Architecture

Advanced variable interpolation with multiple resolution strategies:

```python
class InterpolationEngine:
    """Handles variable interpolation in configuration values"""

    def __init__(self):
        self.resolvers = []
        self.variable_pattern = re.compile(r'\$\{([^}]+)\}')
        self.circular_reference_detector = CircularReferenceDetector()

    def add_resolver(self, resolver: VariableResolver):
        """Add a variable resolver to the chain"""
        self.resolvers.append(resolver)

    def interpolate(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Perform variable interpolation on configuration data"""
        interpolated = deepcopy(data)

        # Build dependency graph
        dependencies = self._build_dependency_graph(interpolated)

        # Check for circular references
        if self.circular_reference_detector.has_cycles(dependencies):
            cycles = self.circular_reference_detector.find_cycles(dependencies)
            raise CircularReferenceError(f"Circular references detected: {cycles}")

        # Resolve variables in dependency order
        resolution_order = self._topological_sort(dependencies)

        for variable_path in resolution_order:
            self._resolve_variable_at_path(interpolated, variable_path)

        return interpolated

    def _resolve_variable_at_path(self, data: Dict[str, Any], path: str):
        """Resolve variables at a specific path"""
        value = self._get_path_value(data, path)

        if isinstance(value, str) and self.variable_pattern.search(value):
            resolved_value = self._resolve_string_variables(value, data)
            self._set_path_value(data, path, resolved_value)
```

### Variable Resolver Types

#### Environment Variable Resolver
```python
class EnvironmentResolver(VariableResolver):
    """Resolves variables from environment"""

    def __init__(self, prefix: str = ""):
        self.prefix = prefix
        self.cache = {}

    def can_resolve(self, variable: str) -> bool:
        """Check if this resolver can handle the variable"""
        return variable.startswith("ENV_") or not "." in variable

    def resolve(self, variable: str, context: Dict[str, Any]) -> Optional[str]:
        """Resolve environment variable"""
        if variable in self.cache:
            return self.cache[variable]

        # Try direct environment lookup
        env_value = os.getenv(variable)
        if env_value is not None:
            self.cache[variable] = env_value
            return env_value

        # Try with prefix
        if self.prefix:
            prefixed_var = f"{self.prefix}_{variable}"
            env_value = os.getenv(prefixed_var)
            if env_value is not None:
                self.cache[variable] = env_value
                return env_value

        return None
```

#### Configuration Reference Resolver
```python
class ConfigResolver(VariableResolver):
    """Resolves variables from other configuration values"""

    def can_resolve(self, variable: str) -> bool:
        return "." in variable  # Dot notation indicates config reference

    def resolve(self, variable: str, context: Dict[str, Any]) -> Optional[str]:
        """Resolve configuration reference using dot notation"""
        try:
            parts = variable.split(".")
            current = context

            for part in parts:
                if isinstance(current, dict) and part in current:
                    current = current[part]
                else:
                    return None

            # Convert to string for interpolation
            return str(current) if current is not None else None

        except (KeyError, TypeError):
            return None
```

#### Function Resolver
```python
class FunctionResolver(VariableResolver):
    """Resolves variables using function calls"""

    def __init__(self):
        self.functions = {
            'now': lambda: datetime.now().isoformat(),
            'uuid': lambda: str(uuid.uuid4()),
            'hostname': lambda: socket.gethostname(),
            'user': lambda: getpass.getuser(),
            'random': lambda min_val=0, max_val=100: random.randint(min_val, max_val),
            'base64_encode': lambda value: base64.b64encode(value.encode()).decode(),
            'base64_decode': lambda value: base64.b64decode(value).decode()
        }

    def can_resolve(self, variable: str) -> bool:
        func_name = variable.split('(')[0] if '(' in variable else variable
        return func_name in self.functions

    def resolve(self, variable: str, context: Dict[str, Any]) -> Optional[str]:
        """Resolve function call"""
        if '(' in variable:
            # Function with arguments: func_name(arg1, arg2)
            func_name, args_str = variable.split('(', 1)
            args_str = args_str.rstrip(')')

            if func_name in self.functions:
                try:
                    # Parse arguments (simplified - could be more sophisticated)
                    args = [arg.strip().strip('"\'') for arg in args_str.split(',') if arg.strip()]
                    result = self.functions[func_name](*args)
                    return str(result)
                except Exception:
                    return None
        else:
            # Function without arguments
            if variable in self.functions:
                try:
                    result = self.functions[variable]()
                    return str(result)
                except Exception:
                    return None

        return None
```

### Advanced Interpolation Features

#### Conditional Interpolation
```toml
[database]
host = "${if:production:prod-server:localhost}"
debug = "${not:production}"

[logging]
level = "${switch:environment:development=DEBUG,staging=INFO,production=WARN}"
```

#### Default Values and Fallbacks
```toml
[api]
# Use environment variable with fallback
base_url = "${API_BASE_URL:https://api.example.com}"

# Chain of fallbacks
database_url = "${DATABASE_URL:${DB_HOST}/${DB_NAME}:sqlite:///local.db}"
```

---

## Encryption Architecture

### Encryption System Design

Transparent encryption/decryption of sensitive configuration values:

```python
class ConfigEncryption:
    """Handles encryption and decryption of configuration values"""

    def __init__(self, key: Union[str, bytes]):
        self.key = self._derive_key(key)
        self.cipher_suite = Fernet(self.key)
        self.encrypted_prefix = "encrypted:"
        self.algorithms = {
            "AES256": self._decrypt_aes256,
            "FERNET": self._decrypt_fernet
        }

    def encrypt_value(self, value: str, algorithm: str = "FERNET") -> str:
        """Encrypt a configuration value"""
        if algorithm == "FERNET":
            encrypted = self.cipher_suite.encrypt(value.encode())
            encoded = base64.b64encode(encrypted).decode()
            return f"{self.encrypted_prefix}{algorithm}:{encoded}"
        else:
            raise ValueError(f"Unsupported encryption algorithm: {algorithm}")

    def decrypt_value(self, encrypted_value: str) -> str:
        """Decrypt a configuration value"""
        if not self._is_encrypted(encrypted_value):
            return encrypted_value  # Not encrypted, return as-is

        try:
            # Parse encrypted value format
            parts = encrypted_value[len(self.encrypted_prefix):].split(':', 2)
            if len(parts) < 2:
                raise ValueError("Invalid encrypted value format")

            algorithm, encoded_data = parts[0], parts[1]

            if algorithm in self.algorithms:
                return self.algorithms[algorithm](encoded_data)
            else:
                raise ValueError(f"Unknown encryption algorithm: {algorithm}")

        except Exception as e:
            raise ConfigError(f"Failed to decrypt configuration value: {e}")

    def _is_encrypted(self, value: str) -> bool:
        """Check if a value is encrypted"""
        return isinstance(value, str) and value.startswith(self.encrypted_prefix)

    def scan_and_decrypt(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Recursively scan and decrypt encrypted values in configuration"""
        decrypted = {}

        for key, value in data.items():
            if isinstance(value, dict):
                decrypted[key] = self.scan_and_decrypt(value)
            elif isinstance(value, str) and self._is_encrypted(value):
                decrypted[key] = self.decrypt_value(value)
            else:
                decrypted[key] = value

        return decrypted
```

### Key Management

Secure key derivation and management:

```python
def derive_app_key(app_name: str, user_key: Optional[str] = None) -> bytes:
    """Derive application-specific encryption key"""
    if user_key:
        # User-provided key
        key_material = user_key.encode()
    else:
        # Derive from environment and application
        hostname = socket.gethostname()
        username = getpass.getuser()
        key_material = f"{app_name}:{hostname}:{username}".encode()

    # Use PBKDF2 for key derivation
    salt = b"xlibrary_config_salt"  # In practice, use random salt per app
    key = PBKDF2(key_material, salt, dkLen=32, count=100000)

    return base64.urlsafe_b64encode(key)

class SecureKeyManager:
    """Manages encryption keys securely"""

    def __init__(self, app_name: str):
        self.app_name = app_name
        self.key_cache = {}

    def get_key(self, key_id: Optional[str] = None) -> bytes:
        """Get encryption key by ID"""
        if key_id is None:
            key_id = "default"

        if key_id in self.key_cache:
            return self.key_cache[key_id]

        # Try environment variable
        env_key = os.getenv(f"{self.app_name.upper()}_ENCRYPTION_KEY_{key_id.upper()}")
        if env_key:
            key = base64.urlsafe_b64decode(env_key)
            self.key_cache[key_id] = key
            return key

        # Derive application key
        derived_key = derive_app_key(self.app_name)
        self.key_cache[key_id] = derived_key
        return derived_key
```

---

## Hierarchical Configuration

### Configuration Merging Strategy

Intelligent merging of configuration from multiple sources:

```python
class ConfigurationMerger:
    """Handles merging of configuration from multiple sources"""

    def __init__(self, merge_strategy: str = "deep"):
        self.merge_strategy = merge_strategy
        self.merge_functions = {
            "deep": self._deep_merge,
            "shallow": self._shallow_merge,
            "replace": self._replace_merge
        }

    def merge_configurations(self, configs: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Merge multiple configuration dictionaries"""
        if not configs:
            return {}

        merged = configs[0].copy()

        for config in configs[1:]:
            merged = self.merge_functions[self.merge_strategy](merged, config)

        return merged

    def _deep_merge(self, base: Dict[str, Any], overlay: Dict[str, Any]) -> Dict[str, Any]:
        """Deep merge configuration dictionaries"""
        result = base.copy()

        for key, value in overlay.items():
            if key in result and isinstance(result[key], dict) and isinstance(value, dict):
                # Recursively merge dictionaries
                result[key] = self._deep_merge(result[key], value)
            elif key in result and isinstance(result[key], list) and isinstance(value, list):
                # Merge lists based on configuration
                result[key] = self._merge_lists(result[key], value)
            else:
                # Replace value
                result[key] = value

        return result

    def _merge_lists(self, base_list: List[Any], overlay_list: List[Any]) -> List[Any]:
        """Merge configuration lists"""
        # Strategy: extend base with overlay items
        # Could be configured for different strategies (replace, union, etc.)
        return base_list + overlay_list
```

### Environment-Specific Configuration

Support for environment-specific configuration sections:

```python
class EnvironmentSelector:
    """Selects and applies environment-specific configuration"""

    def __init__(self, environment: Optional[str] = None):
        self.environment = environment or self._detect_environment()
        self.environment_precedence = [
            self.environment,
            "default",
            "base"
        ]

    def _detect_environment(self) -> str:
        """Auto-detect current environment"""
        # Check environment variables
        env = os.getenv("APP_ENV") or os.getenv("ENVIRONMENT") or os.getenv("ENV")
        if env:
            return env

        # Check for common environment indicators
        if os.getenv("DEVELOPMENT") or os.path.exists(".env.development"):
            return "development"
        elif os.getenv("STAGING"):
            return "staging"
        elif os.getenv("PRODUCTION"):
            return "production"

        return "development"  # Default fallback

    def apply_environment_config(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """Apply environment-specific configuration"""
        result = config.copy()

        for env_name in reversed(self.environment_precedence):
            if env_name in config:
                env_config = config[env_name]
                result = self._merge_environment_section(result, env_config)
                # Remove environment section after merging
                result.pop(env_name, None)

        return result

    def _merge_environment_section(self, base: Dict[str, Any], env_section: Dict[str, Any]) -> Dict[str, Any]:
        """Merge environment-specific configuration section"""
        merger = ConfigurationMerger("deep")
        return merger.merge_configurations([base, env_section])
```

---

## Auto-Reload Mechanism

### File Watching System

Efficient file change detection for configuration auto-reload:

```python
class ConfigurationWatcher:
    """Watches configuration files for changes and triggers reload"""

    def __init__(self, config_manager: 'ConfigManager'):
        self.config_manager = config_manager
        self.observer = Observer()
        self.file_handlers = {}
        self.last_reload = time.time()
        self.reload_debounce = 1.0  # Minimum time between reloads

    def start_watching(self, files: List[Path]):
        """Start watching configuration files"""
        for file_path in files:
            if file_path.exists():
                handler = ConfigFileHandler(self._on_file_change, file_path)
                self.file_handlers[str(file_path)] = handler
                self.observer.schedule(handler, str(file_path.parent), recursive=False)

        self.observer.start()

    def _on_file_change(self, file_path: Path):
        """Handle configuration file change"""
        current_time = time.time()

        # Debounce rapid changes
        if current_time - self.last_reload < self.reload_debounce:
            return

        try:
            # Validate configuration before reloading
            temp_config = self._validate_changed_config(file_path)

            if temp_config.is_valid:
                # Reload configuration
                self.config_manager._reload_configuration()
                self.last_reload = current_time

                # Notify listeners
                self._notify_reload_listeners(file_path, temp_config)
            else:
                # Log validation errors but don't reload
                self._log_validation_errors(file_path, temp_config)

        except Exception as e:
            # Log error but don't crash
            logger.error(f"Error during configuration reload: {e}")

    def _validate_changed_config(self, changed_file: Path) -> ValidationResult:
        """Validate configuration after file change"""
        try:
            # Create temporary config manager to test the change
            temp_config = ConfigManager(
                sources=self.config_manager._sources,
                schema=self.config_manager._schema
            )

            return ValidationResult(is_valid=True, data=temp_config._data)

        except Exception as e:
            return ValidationResult(
                is_valid=False,
                errors=[ConfigError(f"Configuration validation failed: {e}")]
            )

class ConfigFileHandler(FileSystemEventHandler):
    """File system event handler for configuration files"""

    def __init__(self, callback, target_file: Path):
        self.callback = callback
        self.target_file = target_file

    def on_modified(self, event):
        if not event.is_directory and Path(event.src_path) == self.target_file:
            self.callback(self.target_file)
```

---

## Performance Engineering

### Caching and Optimization

Efficient caching system for configuration access:

```python
class ConfigCache:
    """Caches configuration values for fast access"""

    def __init__(self, max_size: int = 1000, ttl: float = 3600.0):
        self.cache = {}
        self.access_times = {}
        self.max_size = max_size
        self.ttl = ttl

    def get(self, key: str) -> Optional[Any]:
        """Get cached configuration value"""
        if key in self.cache:
            # Check TTL
            if time.time() - self.access_times[key] < self.ttl:
                return self.cache[key]
            else:
                # Expired
                self._remove(key)

        return None

    def set(self, key: str, value: Any):
        """Cache configuration value"""
        # Evict if at capacity
        if len(self.cache) >= self.max_size:
            self._evict_lru()

        self.cache[key] = value
        self.access_times[key] = time.time()

    def _evict_lru(self):
        """Evict least recently used item"""
        if not self.access_times:
            return

        lru_key = min(self.access_times, key=self.access_times.get)
        self._remove(lru_key)

    def _remove(self, key: str):
        """Remove item from cache"""
        self.cache.pop(key, None)
        self.access_times.pop(key, None)

    def invalidate(self, prefix: str = ""):
        """Invalidate cache entries"""
        if prefix:
            keys_to_remove = [k for k in self.cache.keys() if k.startswith(prefix)]
            for key in keys_to_remove:
                self._remove(key)
        else:
            self.cache.clear()
            self.access_times.clear()
```

### Lazy Loading and Initialization

Efficient loading strategies:

```python
class LazyConfigManager:
    """Configuration manager with lazy loading"""

    def __init__(self, *args, **kwargs):
        self._args = args
        self._kwargs = kwargs
        self._loaded = False
        self._data = None
        self._lock = threading.RLock()

    def _ensure_loaded(self):
        """Ensure configuration is loaded"""
        if not self._loaded:
            with self._lock:
                if not self._loaded:  # Double-check pattern
                    self._load_configuration()
                    self._loaded = True

    def get(self, key: str, default: Any = None, type: Optional[Type] = None) -> Any:
        """Get configuration value with lazy loading"""
        self._ensure_loaded()
        return self._get_value(key, default, type)

    def _load_configuration(self):
        """Load configuration (called only when needed)"""
        # Actual loading logic here
        pass
```

---

**The Config Manager represents sophisticated configuration management with enterprise-grade features while maintaining simplicity for basic use cases.** ‚öôÔ∏è

---

## Next Steps

- **[User Guide Overview](02.03%20Chapter%202%20-%20Config%20Manager%20-%20User%20Guide%20-%20Overview.md)** - Practical quick-start guide
- **[User Guide Detailed](02.04%20Chapter%202%20-%20Config%20Manager%20-%20User%20Guide%20-%20Detailed.md)** - Comprehensive feature documentation
- **[Chapter 3: Download Manager](03.01%20Chapter%203%20-%20Download%20Manager%20-%20Design%20-%20Overview.md)** - Advanced download system