# Chapter 3: Download Manager - Detailed User Guide

> **📚 COMPREHENSIVE FEATURE REFERENCE**
> Complete coverage of all Download Manager features, advanced configuration, queue management, and production deployment patterns.

## Table of Contents

- [Advanced Configuration](#advanced-configuration)
- [Convenience Functions and One-Off Downloads](#convenience-functions-and-one-off-downloads)
- [Transcript Processing and Conversion](#transcript-processing-and-conversion)
- [Queue Management](#queue-management)
- [Progress Monitoring](#progress-monitoring)
- [Fallback Strategies](#fallback-strategies)
- [Batch Operations](#batch-operations)
- [Format and Quality Control](#format-and-quality-control)
- [Production Deployment](#production-deployment)
- [Integration Patterns](#integration-patterns)
- [Performance Optimization](#performance-optimization)
- [Advanced Use Cases](#advanced-use-cases)

---

## Advanced Configuration

### Complete DownloadConfig Reference

```python
from xlibrary.download import DownloadConfig, VideoQuality

config = DownloadConfig(
    # Output settings
    output_dir="/path/to/downloads",
    output_template="%(uploader)s/%(title)s.%(ext)s",
    create_directories=True,
    overwrite_existing=False,

    # Quality and format
    quality=VideoQuality.HD_720P,      # or "720p", "best", "worst"
    format="mp4",                      # Output format
    audio_codec="aac",                 # Audio codec preference
    video_codec="h264",                # Video codec preference

    # Audio-specific settings
    audio_only=False,
    audio_quality="192k",              # Audio bitrate
    normalize_audio=True,              # Normalize audio levels

    # Metadata and extras
    embed_subtitles=True,              # Include subtitle tracks
    auto_subtitles=True,               # Download auto-generated subtitles
    subtitle_languages=["en", "es"],   # Preferred subtitle languages
    embed_metadata=True,               # Include video metadata
    embed_artwork=True,                # Include thumbnail as artwork
    write_info_json=True,              # Save metadata JSON file
    write_description=True,            # Save video description
    write_annotations=False,           # Save annotations (deprecated)

    # Download behavior
    timeout=300,                       # Request timeout in seconds
    max_retries=3,                     # Number of retry attempts
    retry_delay=5,                     # Delay between retries
    resume_downloads=True,             # Resume partial downloads

    # Rate limiting and politeness
    rate_limit_mbps=None,             # Bandwidth limit in Mbps
    request_delay=0,                   # Delay between requests
    respect_robots_txt=True,           # Respect robots.txt

    # Playlist and batch settings
    max_downloads=None,                # Limit number of downloads
    start_number=1,                    # Start position in playlist
    end_number=None,                   # End position in playlist
    download_archive="archive.txt",    # Track downloaded items
    ignore_errors=False,               # Continue on individual failures

    # Advanced options
    use_cookies=False,                 # Use browser cookies
    cookie_file="cookies.txt",         # Cookie file path
    user_agent="xlibrary/1.0",        # Custom user agent
    proxy_url=None,                    # HTTP proxy
    headers={},                        # Custom HTTP headers

    # Post-processing
    convert_format=None,               # Convert to different format
    embed_chapters=False,              # Embed chapter markers
    remove_source_files=False,        # Delete original after conversion

    # Validation
    min_file_size="1MB",              # Minimum file size
    max_file_size="2GB",              # Maximum file size
    verify_download=True               # Verify download integrity
)
```

### Environment-Based Configuration

```python
import os
from xlibrary.download import DownloadConfig, DownloadManager

def create_production_config():
    """Create production-optimized download configuration"""
    return DownloadConfig(
        output_dir=os.getenv("DOWNLOAD_OUTPUT_DIR", "/data/downloads"),
        max_retries=int(os.getenv("DOWNLOAD_MAX_RETRIES", "5")),
        timeout=int(os.getenv("DOWNLOAD_TIMEOUT", "300")),
        rate_limit_mbps=float(os.getenv("DOWNLOAD_RATE_LIMIT", "0")),
        download_archive=os.getenv("DOWNLOAD_ARCHIVE", "archive.txt"),
        ignore_errors=os.getenv("DOWNLOAD_IGNORE_ERRORS", "false").lower() == "true",

        # Security settings
        verify_download=True,
        respect_robots_txt=True,
        user_agent=os.getenv("DOWNLOAD_USER_AGENT", "xlibrary-bot/1.0")
    )

def create_development_config():
    """Create development-friendly configuration"""
    return DownloadConfig(
        output_dir="./downloads",
        quality="720p",  # Reasonable quality for testing
        max_downloads=5,  # Limit for testing
        write_info_json=True,  # Helpful for debugging
        ignore_errors=True,  # Continue on errors during testing
        timeout=60  # Shorter timeout for development
    )

# Usage based on environment
env = os.getenv("ENVIRONMENT", "development")
if env == "production":
    default_config = create_production_config()
else:
    default_config = create_development_config()

dm = DownloadManager(default_config=default_config)
```

### Configuration Profiles

```python
from xlibrary.download import DownloadConfig

class ConfigProfiles:
    """Predefined configuration profiles for common use cases"""

    @staticmethod
    def podcast_profile():
        """Optimized for podcast downloads"""
        return DownloadConfig(
            audio_only=True,
            audio_quality="128k",
            format="mp3",
            normalize_audio=True,
            embed_metadata=True,
            embed_artwork=True,
            output_template="Podcasts/%(uploader)s/%(title)s.%(ext)s",
            download_archive="podcast_archive.txt"
        )

    @staticmethod
    def music_profile():
        """Optimized for music downloads"""
        return DownloadConfig(
            audio_only=True,
            audio_quality="320k",
            format="mp3",
            embed_metadata=True,
            embed_artwork=True,
            normalize_audio=True,
            output_template="Music/%(artist)s/%(album)s/%(title)s.%(ext)s"
        )

    @staticmethod
    def video_archive_profile():
        """For archival-quality video downloads"""
        return DownloadConfig(
            quality="best",
            format="mkv",  # Container that supports multiple tracks
            embed_subtitles=True,
            subtitle_languages=["en", "es", "fr"],
            embed_metadata=True,
            write_info_json=True,
            write_description=True,
            embed_chapters=True,
            output_template="Archive/%(uploader)s/%(upload_date>%Y-%m-%d)s - %(title)s.%(ext)s"
        )

    @staticmethod
    def social_media_profile():
        """Optimized for social media content"""
        return DownloadConfig(
            quality="720p",
            format="mp4",
            max_file_size="100MB",
            embed_metadata=True,
            output_template="SocialMedia/%(platform)s/%(uploader)s/%(title)s.%(ext)s",
            ignore_errors=True,  # Social media posts may be deleted
            request_delay=2  # Be respectful to social media APIs
        )

    @staticmethod
    def live_stream_profile():
        """For live stream recording"""
        return DownloadConfig(
            quality="720p",
            format="mp4",
            timeout=3600,  # 1 hour timeout for streams
            max_retries=10,  # More retries for unstable streams
            retry_delay=30,  # Longer delay for stream recovery
            resume_downloads=True,
            output_template="Streams/%(uploader)s/%(upload_date>%Y-%m-%d)s - %(title)s.%(ext)s"
        )

# Usage
dm = DownloadManager()

# Use predefined profiles
podcast_task = dm.add_download(podcast_url, config=ConfigProfiles.podcast_profile())
music_task = dm.add_download(music_url, config=ConfigProfiles.music_profile())
video_task = dm.add_download(video_url, config=ConfigProfiles.video_archive_profile())
```

---

## Convenience Functions and One-Off Downloads

### Simple Download Functions

The Download Manager provides convenience functions for quick, one-off downloads without needing to manage a full DownloadManager instance. These functions are perfect for scripts, notebooks, and simple automation tasks.

**Purpose**: These examples demonstrate how to quickly download content without complex configuration. Each function handles the complete lifecycle: initialization, download, and cleanup.

```python
from xlibrary.download import get_audio, get_video, get_transcript, get_content

# Quick audio extraction from video
# This example shows: extracting audio from a YouTube video for podcast-like content
audio_file = get_audio(
    "https://youtube.com/watch?v=dQw4w9WgXcQ",
    output_dir="~/Music",
    format="mp3",
    quality="192k"
)
print(f"Audio saved: {audio_file}")

# Quick video download with quality control
# This example shows: downloading video with specific quality and format constraints
video_file = get_video(
    "https://youtube.com/watch?v=dQw4w9WgXcQ",
    output_dir="~/Videos",
    quality="720p",
    format="mp4"
)
print(f"Video saved: {video_file}")

# Quick transcript/subtitle download
# This example shows: extracting text content from videos for accessibility or analysis
transcript_file = get_transcript(
    "https://youtube.com/watch?v=dQw4w9WgXcQ",
    output_dir="~/Documents",
    languages=["en", "es"]  # Try English first, then Spanish
)
print(f"Transcript saved: {transcript_file}")
```

### Multi-Content Download

**Purpose**: This example demonstrates downloading multiple content types from a single source - useful for creating complete content archives or when you need both video and accompanying materials.

```python
from xlibrary.download import get_content

# Download multiple content types from one URL
# This example shows: comprehensive content extraction for research or archival purposes
result = get_content(
    "https://youtube.com/watch?v=dQw4w9WgXcQ",
    output_dir="~/Downloads/complete_archive",
    include_audio=True,          # Extract audio track
    include_video=True,          # Download video file
    include_transcript=True,     # Get subtitles/transcript
    audio_format="mp3",
    video_format="mp4",
    video_quality="720p",
    transcript_languages=["en", "es", "fr"]
)

# The result contains paths to all downloaded content
if "audio_file" in result:
    print(f"Audio: {result['audio_file']}")
if "video_file" in result:
    print(f"Video: {result['video_file']}")
if "transcript_file" in result:
    print(f"Transcript: {result['transcript_file']}")

# Handle any errors that occurred during specific content type downloads
for error_key in ["audio_error", "video_error", "transcript_error"]:
    if error_key in result:
        print(f"Warning - {error_key}: {result[error_key]}")
```

### Batch Downloads with Convenience Functions

**Purpose**: This example shows how to process multiple URLs efficiently using convenience functions - ideal for processing lists of content from spreadsheets, APIs, or user inputs.

```python
from xlibrary.download import get_audio_batch

# Batch audio extraction from multiple sources
# This example shows: processing a playlist or list of videos for audio-only content
podcast_urls = [
    "https://youtube.com/watch?v=episode1",
    "https://youtube.com/watch?v=episode2",
    "https://youtube.com/watch?v=episode3",
    "https://soundcloud.com/podcast/episode4"
]

# Download all as audio files with controlled concurrency
audio_files = get_audio_batch(
    podcast_urls,
    output_dir="~/Podcasts",
    format="mp3",
    max_concurrent=3  # Limit concurrent downloads to be respectful
)

# Process results - successful downloads and errors
for i, result in enumerate(audio_files):
    if result.startswith("Error:"):
        print(f"Failed to download {podcast_urls[i]}: {result}")
    else:
        print(f"Downloaded: {result}")
```

### URL Analysis and Format Discovery

**Purpose**: These examples demonstrate how to inspect content before downloading - useful for making informed decisions about quality, format, and download strategy.

```python
from xlibrary.download import get_info, get_available_formats, get_optimal_format

# Get detailed information about a video without downloading
# This example shows: content inspection for metadata extraction or download planning
url = "https://youtube.com/watch?v=dQw4w9WgXcQ"
info = get_info(url)

if info:
    print(f"Title: {info.title}")
    print(f"Uploader: {info.uploader}")
    print(f"Duration: {info.duration} seconds")
    print(f"View count: {info.view_count:,}")
    print(f"Upload date: {info.upload_date}")
    print(f"Description: {info.description[:100]}...")

# Discover available formats and qualities
# This example shows: understanding what options are available before downloading
formats = get_available_formats(url)
print(f"\nAvailable video formats: {formats['video_formats']}")
print(f"Available audio formats: {formats['audio_formats']}")
print(f"Available qualities: {formats['qualities']}")
print(f"Subtitle languages: {formats['subtitle_languages']}")
print(f"Video codecs: {formats['codecs']['video']}")
print(f"Audio codecs: {formats['codecs']['audio']}")

# Get optimal format recommendations based on platform
# This example shows: intelligent format selection based on target platform compatibility
mac_optimal = get_optimal_format(url, content_type="video", platform="mac")
print(f"\nOptimal for Mac:")
print(f"  Format: {mac_optimal['format']}")
print(f"  Quality: {mac_optimal['quality']}")
print(f"  Codec: {mac_optimal['codec']}")

windows_optimal = get_optimal_format(url, content_type="audio", platform="windows")
print(f"\nOptimal audio for Windows:")
print(f"  Format: {windows_optimal['format']}")
print(f"  Quality: {windows_optimal['quality']}")
print(f"  Codec: {windows_optimal['codec']}")
```

---

## Transcript Processing and Conversion

### Transcript Download and Conversion

**Purpose**: This section demonstrates the complete transcript workflow - from download to clean, readable formats. This is essential for content analysis, accessibility improvements, and creating text-based content from video sources.

```python
from xlibrary.download import get_transcript_markdown, convert_transcript_to_markdown

# Download transcript and convert to markdown in one step
# This example shows: getting clean, readable text from video content for documentation or analysis
url = "https://youtube.com/watch?v=educational_video"
result = get_transcript_markdown(
    url,
    output_dir="~/Documents/transcripts",
    languages=["en"],                    # Prefer English subtitles
    paragraph_min_words=15,              # Minimum words per paragraph for readability
    preserve_speaker_labels=True,        # Keep speaker identification if available
    timeout=300
)

print("Transcript Processing Results:")
print(f"Original transcript: {result['transcript_file']}")
print(f"Markdown version: {result['markdown_file']}")
print(f"Word count: {result['word_count']:,}")
print(f"Paragraph count: {result['paragraph_count']}")
print(f"Average words per paragraph: {result['conversion_stats']['average_words_per_paragraph']:.1f}")
```

### Manual Transcript Conversion

**Purpose**: This example shows how to convert existing transcript files (VTT, SRT, etc.) to clean markdown format - useful when you already have transcript files from other sources.

```python
from xlibrary.download import convert_transcript_to_markdown

# Convert existing transcript files to markdown
# This example shows: cleaning up transcript files for better readability and processing
transcript_formats = [
    ("meeting_recording.vtt", "WebVTT from video conferencing"),
    ("podcast_episode.srt", "SRT from podcast platform"),
    ("lecture_notes.ttml", "TTML from educational platform")
]

for transcript_file, description in transcript_formats:
    print(f"\nProcessing {description}:")

    try:
        conversion_result = convert_transcript_to_markdown(
            transcript_file,
            paragraph_min_words=20,          # Longer paragraphs for formal content
            preserve_speaker_labels=True
        )

        print(f"✅ Conversion successful!")
        print(f"   Input: {conversion_result['input_file']}")
        print(f"   Output: {conversion_result['output_file']}")
        print(f"   Word count: {conversion_result['word_count']:,}")
        print(f"   Paragraphs: {conversion_result['paragraph_count']}")
        print(f"   Size reduction: {conversion_result['compression_ratio']:.1%}")

    except FileNotFoundError:
        print(f"❌ File not found: {transcript_file}")
    except Exception as e:
        print(f"❌ Conversion failed: {e}")
```

### Advanced Transcript Processing

**Purpose**: This example demonstrates advanced transcript processing techniques including batch conversion, format standardization, and content analysis preparation.

```python
from pathlib import Path
from xlibrary.download import TranscriptConverter

# Batch transcript processing for content analysis
# This example shows: processing multiple transcript files for research or content creation
class TranscriptProcessor:
    def __init__(self, input_directory, output_directory):
        self.input_dir = Path(input_directory)
        self.output_dir = Path(output_directory)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.converter = TranscriptConverter()

    def process_directory(self):
        """Process all transcript files in a directory"""
        supported_extensions = ['.vtt', '.srt', '.ttml', '.txt']
        transcript_files = []

        # Find all transcript files
        for ext in supported_extensions:
            transcript_files.extend(self.input_dir.glob(f"*{ext}"))

        results = []

        for transcript_file in transcript_files:
            print(f"\nProcessing: {transcript_file.name}")

            # Generate output filename
            output_file = self.output_dir / f"{transcript_file.stem}.md"

            try:
                # Convert with custom settings based on content type
                settings = self._get_conversion_settings(transcript_file.name)

                result = self.converter.convert_to_markdown(
                    transcript_file,
                    output_file,
                    **settings
                )

                results.append({
                    'file': transcript_file.name,
                    'status': 'success',
                    'output': output_file,
                    'stats': result
                })

                print(f"✅ Converted: {result['word_count']:,} words, "
                      f"{result['paragraph_count']} paragraphs")

            except Exception as e:
                results.append({
                    'file': transcript_file.name,
                    'status': 'error',
                    'error': str(e)
                })
                print(f"❌ Error: {e}")

        return results

    def _get_conversion_settings(self, filename):
        """Get optimal conversion settings based on content type"""
        filename_lower = filename.lower()

        if 'lecture' in filename_lower or 'presentation' in filename_lower:
            # Academic content: longer paragraphs, preserve structure
            return {
                'paragraph_min_words': 25,
                'preserve_speaker_labels': True
            }
        elif 'podcast' in filename_lower or 'interview' in filename_lower:
            # Conversational content: shorter paragraphs, preserve speakers
            return {
                'paragraph_min_words': 12,
                'preserve_speaker_labels': True
            }
        elif 'meeting' in filename_lower:
            # Meeting content: medium paragraphs, preserve speakers
            return {
                'paragraph_min_words': 15,
                'preserve_speaker_labels': True
            }
        else:
            # Default settings
            return {
                'paragraph_min_words': 15,
                'preserve_speaker_labels': True
            }

    def generate_summary_report(self, results):
        """Generate processing summary report"""
        successful = [r for r in results if r['status'] == 'success']
        failed = [r for r in results if r['status'] == 'error']

        total_words = sum(r['stats']['word_count'] for r in successful)
        total_paragraphs = sum(r['stats']['paragraph_count'] for r in successful)

        print(f"\n📊 Processing Summary:")
        print(f"   Total files processed: {len(results)}")
        print(f"   Successful conversions: {len(successful)}")
        print(f"   Failed conversions: {len(failed)}")
        print(f"   Total words extracted: {total_words:,}")
        print(f"   Total paragraphs created: {total_paragraphs:,}")

        if failed:
            print(f"\n❌ Failed files:")
            for failure in failed:
                print(f"   - {failure['file']}: {failure['error']}")

# Usage: Process a directory of transcript files
processor = TranscriptProcessor("./raw_transcripts", "./clean_transcripts")
results = processor.process_directory()
processor.generate_summary_report(results)
```

### Integration with Content Analysis

**Purpose**: This example shows how to integrate transcript processing with content analysis tools - demonstrating practical applications for research, SEO, and content creation workflows.

```python
import re
from collections import Counter
from xlibrary.download import get_transcript_markdown

# Download and analyze video content for insights
# This example shows: complete workflow from video to content insights
def analyze_video_content(video_url, analysis_type="keywords"):
    """
    Download transcript and perform content analysis

    analysis_type options:
    - "keywords": Extract most common keywords
    - "topics": Identify main topics and themes
    - "sentiment": Basic sentiment analysis
    - "structure": Analyze content structure and flow
    """

    print(f"📺 Analyzing video: {video_url}")

    # Download and convert transcript
    result = get_transcript_markdown(
        video_url,
        paragraph_min_words=20,
        preserve_speaker_labels=False  # Remove speakers for pure content analysis
    )

    # Read the clean markdown content
    with open(result['markdown_file'], 'r', encoding='utf-8') as f:
        content = f.read()

    print(f"📄 Transcript processed: {result['word_count']:,} words in {result['paragraph_count']} paragraphs")

    if analysis_type == "keywords":
        return analyze_keywords(content)
    elif analysis_type == "topics":
        return analyze_topics(content)
    elif analysis_type == "structure":
        return analyze_structure(content)
    else:
        return {"error": f"Unknown analysis type: {analysis_type}"}

def analyze_keywords(content):
    """Extract and rank keywords from transcript content"""
    # Clean and tokenize content
    words = re.findall(r'\b[a-zA-Z]{4,}\b', content.lower())  # Words 4+ chars

    # Remove common stop words
    stop_words = {
        'that', 'with', 'have', 'this', 'will', 'from', 'they', 'been',
        'their', 'said', 'each', 'which', 'more', 'like', 'what', 'when',
        'where', 'would', 'could', 'should', 'about', 'there', 'think'
    }

    filtered_words = [word for word in words if word not in stop_words]
    word_counts = Counter(filtered_words)

    return {
        "analysis_type": "keywords",
        "top_keywords": word_counts.most_common(20),
        "unique_words": len(set(filtered_words)),
        "total_words": len(filtered_words),
        "vocabulary_richness": len(set(filtered_words)) / len(filtered_words) if filtered_words else 0
    }

def analyze_topics(content):
    """Identify main topics and themes"""
    paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]

    # Simple topic detection based on keyword clustering
    tech_keywords = ['technology', 'software', 'computer', 'digital', 'programming', 'code', 'data']
    business_keywords = ['business', 'company', 'market', 'strategy', 'revenue', 'growth', 'sales']
    science_keywords = ['research', 'study', 'experiment', 'analysis', 'theory', 'scientific']

    topic_scores = {
        'technology': sum(1 for p in paragraphs for kw in tech_keywords if kw in p.lower()),
        'business': sum(1 for p in paragraphs for kw in business_keywords if kw in p.lower()),
        'science': sum(1 for p in paragraphs for kw in science_keywords if kw in p.lower())
    }

    return {
        "analysis_type": "topics",
        "topic_scores": topic_scores,
        "dominant_topic": max(topic_scores, key=topic_scores.get),
        "paragraph_count": len(paragraphs),
        "avg_paragraph_length": sum(len(p.split()) for p in paragraphs) / len(paragraphs) if paragraphs else 0
    }

def analyze_structure(content):
    """Analyze content structure and organization"""
    paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]

    # Analyze paragraph lengths and structure
    paragraph_lengths = [len(p.split()) for p in paragraphs]

    # Look for structural elements
    question_paragraphs = sum(1 for p in paragraphs if '?' in p)
    exclamation_paragraphs = sum(1 for p in paragraphs if '!' in p)

    return {
        "analysis_type": "structure",
        "paragraph_count": len(paragraphs),
        "avg_paragraph_length": sum(paragraph_lengths) / len(paragraph_lengths) if paragraph_lengths else 0,
        "shortest_paragraph": min(paragraph_lengths) if paragraph_lengths else 0,
        "longest_paragraph": max(paragraph_lengths) if paragraph_lengths else 0,
        "question_paragraphs": question_paragraphs,
        "exclamation_paragraphs": exclamation_paragraphs,
        "content_style": "conversational" if question_paragraphs > len(paragraphs) * 0.1 else "formal"
    }

# Example usage: Analyze different types of content
educational_video = "https://youtube.com/watch?v=educational_content"
business_video = "https://youtube.com/watch?v=business_presentation"

# Keyword analysis
keywords_result = analyze_video_content(educational_video, "keywords")
print(f"\n🔍 Top Keywords: {keywords_result['top_keywords'][:5]}")
print(f"Vocabulary richness: {keywords_result['vocabulary_richness']:.3f}")

# Topic analysis
topics_result = analyze_video_content(business_video, "topics")
print(f"\n📋 Dominant topic: {topics_result['dominant_topic']}")
print(f"Topic distribution: {topics_result['topic_scores']}")

# Structure analysis
structure_result = analyze_video_content(educational_video, "structure")
print(f"\n📐 Content style: {structure_result['content_style']}")
print(f"Average paragraph length: {structure_result['avg_paragraph_length']:.1f} words")
```

---

## Queue Management

### Advanced Queue Operations

```python
from xlibrary.download import DownloadManager, DownloadStatus
import time

class AdvancedQueueManager:
    def __init__(self, queue_file="advanced_queue.json"):
        self.dm = DownloadManager(
            queue_file=queue_file,
            max_concurrent=5
        )

        # Set up comprehensive callbacks
        self.dm.set_progress_callback(self.on_progress)
        self.dm.set_completion_callback(self.on_completion)
        self.dm.set_error_callback(self.on_error)

        self.stats = {
            'total_added': 0,
            'completed': 0,
            'failed': 0,
            'bytes_downloaded': 0
        }

    def add_priority_download(self, url, priority=0, **config_kwargs):
        """Add download with specific priority"""
        task_id = self.dm.add_download(url, priority=priority, **config_kwargs)
        self.stats['total_added'] += 1
        return task_id

    def add_batch_with_priorities(self, url_priority_pairs):
        """Add multiple downloads with different priorities"""
        task_ids = []

        for url, priority in url_priority_pairs:
            task_id = self.add_priority_download(url, priority=priority)
            task_ids.append(task_id)

        return task_ids

    def pause_queue(self):
        """Pause queue processing"""
        self.dm.pause_queue()
        print("📊 Queue paused")

    def resume_queue(self):
        """Resume queue processing"""
        self.dm.resume_queue()
        print("📊 Queue resumed")

    def cancel_task(self, task_id):
        """Cancel specific download task"""
        return self.dm.cancel_download(task_id)

    def retry_failed_tasks(self):
        """Retry all failed tasks"""
        failed_tasks = self.dm.get_tasks_by_status(DownloadStatus.FAILED)

        for task in failed_tasks:
            print(f"🔄 Retrying failed task: {task.task_id}")
            self.dm.retry_download(task.task_id)

        return len(failed_tasks)

    def clear_completed_tasks(self):
        """Remove completed tasks from queue"""
        completed_count = self.dm.clear_completed_tasks()
        print(f"🧹 Cleared {completed_count} completed tasks")
        return completed_count

    def get_queue_summary(self):
        """Get comprehensive queue summary"""
        status = self.dm.get_queue_status()

        return {
            'queue_status': status,
            'statistics': self.stats,
            'active_downloads': self.dm.get_active_downloads(),
            'estimated_completion_time': self._estimate_completion_time()
        }

    def monitor_queue(self, interval=10):
        """Monitor queue with periodic status updates"""
        while self.dm.has_active_downloads() or self.dm.has_queued_downloads():
            summary = self.get_queue_summary()

            print(f"\n📊 Queue Status Update:")
            print(f"   Active: {summary['queue_status']['active']}")
            print(f"   Queued: {summary['queue_status']['queued']}")
            print(f"   Completed: {summary['queue_status']['completed']}")
            print(f"   Failed: {summary['queue_status']['failed']}")
            print(f"   Total Downloaded: {self._format_bytes(self.stats['bytes_downloaded'])}")

            if summary['estimated_completion_time']:
                print(f"   Est. Completion: {summary['estimated_completion_time']}")

            time.sleep(interval)

    def on_progress(self, task_id, progress):
        """Enhanced progress callback"""
        print(f"📥 {task_id}: {progress.percent:.1f}% "
              f"[{self._format_bytes(progress.bytes_downloaded)}/"
              f"{self._format_bytes(progress.total_bytes)}] "
              f"({progress.download_speed}) - ETA: {progress.eta}")

    def on_completion(self, task_id, result):
        """Enhanced completion callback"""
        self.stats['completed'] += 1
        if result.file_size:
            self.stats['bytes_downloaded'] += result.file_size

        print(f"✅ Completed: {task_id}")
        print(f"   Strategy: {result.strategy_used}")
        print(f"   File: {result.local_path}")
        print(f"   Size: {self._format_bytes(result.file_size)}")

        if result.fallback_attempts:
            print(f"   Fallback attempts: {len(result.fallback_attempts)}")

    def on_error(self, task_id, error):
        """Enhanced error callback"""
        self.stats['failed'] += 1
        print(f"❌ Failed: {task_id}")
        print(f"   Error: {error}")

    def _format_bytes(self, bytes_size):
        """Format bytes to human readable"""
        if not bytes_size:
            return "Unknown"

        for unit in ['B', 'KB', 'MB', 'GB']:
            if bytes_size < 1024:
                return f"{bytes_size:.1f} {unit}"
            bytes_size /= 1024
        return f"{bytes_size:.1f} TB"

    def _estimate_completion_time(self):
        """Estimate remaining completion time"""
        # Implementation would calculate based on current progress
        # This is a simplified version
        active_downloads = self.dm.get_active_downloads()
        if not active_downloads:
            return None

        # Average remaining time based on current progress
        total_eta = 0
        count = 0

        for download in active_downloads:
            if hasattr(download, 'progress') and download.progress.eta:
                total_eta += download.progress.eta
                count += 1

        if count > 0:
            avg_eta = total_eta / count
            return f"{avg_eta:.0f} seconds"

        return "Calculating..."

# Usage Example
queue_manager = AdvancedQueueManager()

# Add downloads with different priorities
urgent_videos = [
    "https://youtube.com/watch?v=urgent1",
    "https://youtube.com/watch?v=urgent2"
]

normal_videos = [
    "https://youtube.com/watch?v=normal1",
    "https://youtube.com/watch?v=normal2",
    "https://youtube.com/watch?v=normal3"
]

low_priority_videos = [
    "https://youtube.com/watch?v=low1",
    "https://youtube.com/watch?v=low2"
]

# Add with priorities (higher number = higher priority)
for url in urgent_videos:
    queue_manager.add_priority_download(url, priority=10)

for url in normal_videos:
    queue_manager.add_priority_download(url, priority=5)

for url in low_priority_videos:
    queue_manager.add_priority_download(url, priority=1)

# Start processing
queue_manager.dm.start_queue()

# Monitor progress
queue_manager.monitor_queue(interval=15)
```

### Queue Persistence and Recovery

```python
from xlibrary.download import DownloadManager
import json
from pathlib import Path

class PersistentQueueManager:
    """Advanced queue management with backup and recovery"""

    def __init__(self, queue_file="downloads.json", backup_interval=300):
        self.queue_file = Path(queue_file)
        self.backup_dir = self.queue_file.parent / "backups"
        self.backup_dir.mkdir(exist_ok=True)
        self.backup_interval = backup_interval

        self.dm = DownloadManager(queue_file=str(self.queue_file))

        # Set up automatic backups
        self._setup_backup_timer()

    def create_backup(self):
        """Create timestamped backup of queue"""
        if not self.queue_file.exists():
            return None

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_file = self.backup_dir / f"queue_backup_{timestamp}.json"

        try:
            import shutil
            shutil.copy2(self.queue_file, backup_file)

            # Keep only last 10 backups
            backups = sorted(self.backup_dir.glob("queue_backup_*.json"))
            if len(backups) > 10:
                for old_backup in backups[:-10]:
                    old_backup.unlink()

            return backup_file

        except Exception as e:
            print(f"Backup failed: {e}")
            return None

    def restore_from_backup(self, backup_file=None):
        """Restore queue from backup"""
        if backup_file is None:
            # Use latest backup
            backups = sorted(self.backup_dir.glob("queue_backup_*.json"))
            if not backups:
                print("No backups found")
                return False
            backup_file = backups[-1]

        try:
            import shutil
            shutil.copy2(backup_file, self.queue_file)

            # Reload the download manager
            self.dm = DownloadManager(queue_file=str(self.queue_file))

            print(f"Restored from backup: {backup_file}")
            return True

        except Exception as e:
            print(f"Restore failed: {e}")
            return False

    def export_queue_summary(self, output_file="queue_summary.json"):
        """Export detailed queue summary"""
        summary = {
            'export_time': datetime.now().isoformat(),
            'total_tasks': len(self.dm.get_all_tasks()),
            'by_status': {},
            'by_source': {},
            'tasks': []
        }

        all_tasks = self.dm.get_all_tasks()

        # Statistics by status
        for task in all_tasks:
            status = str(task.status)
            summary['by_status'][status] = summary['by_status'].get(status, 0) + 1

            # Extract domain for source statistics
            try:
                from urllib.parse import urlparse
                domain = urlparse(task.url).netloc
                summary['by_source'][domain] = summary['by_source'].get(domain, 0) + 1
            except:
                pass

            # Task details
            task_info = {
                'task_id': task.task_id,
                'url': task.url,
                'status': status,
                'created_at': task.created_at.isoformat() if task.created_at else None,
                'completed_at': task.completed_at.isoformat() if task.completed_at else None,
                'file_size': task.result.file_size if task.result else None,
                'local_path': task.result.local_path if task.result else None
            }
            summary['tasks'].append(task_info)

        # Write summary
        with open(output_file, 'w') as f:
            json.dump(summary, f, indent=2)

        print(f"Queue summary exported to: {output_file}")
        return summary

    def _setup_backup_timer(self):
        """Set up periodic backup timer"""
        import threading

        def backup_timer():
            while True:
                time.sleep(self.backup_interval)
                self.create_backup()

        backup_thread = threading.Thread(target=backup_timer, daemon=True)
        backup_thread.start()

# Usage
persistent_queue = PersistentQueueManager(
    queue_file="production_queue.json",
    backup_interval=1800  # Backup every 30 minutes
)

# The queue automatically backs up every 30 minutes
# Manual backup
backup_file = persistent_queue.create_backup()
print(f"Manual backup created: {backup_file}")

# Export summary for analysis
summary = persistent_queue.export_queue_summary("monthly_summary.json")
print(f"Processed {summary['total_tasks']} total downloads")
```

---

## Production Deployment

### Docker Deployment

```dockerfile
# Dockerfile for xlibrary download manager
FROM python:3.11-slim

# Install system dependencies
RUN apt-get update && apt-get install -y \
    ffmpeg \
    wget \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Install xlibrary
RUN pip install xlibrary[download]

# Create app directory
WORKDIR /app

# Copy application code
COPY . .

# Create downloads directory
RUN mkdir -p /app/downloads

# Set environment variables
ENV DOWNLOAD_OUTPUT_DIR=/app/downloads
ENV DOWNLOAD_QUEUE_FILE=/app/queue.json
ENV DOWNLOAD_MAX_CONCURRENT=5

# Expose monitoring port (if using web interface)
EXPOSE 8080

# Run the download manager
CMD ["python", "download_service.py"]
```

```python
# download_service.py - Production download service
import os
import signal
import threading
import time
from xlibrary.download import DownloadManager, DownloadConfig
import logging

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/app/logs/download_service.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

class DownloadService:
    def __init__(self):
        self.dm = DownloadManager(
            queue_file=os.getenv('DOWNLOAD_QUEUE_FILE', '/app/queue.json'),
            default_output_dir=os.getenv('DOWNLOAD_OUTPUT_DIR', '/app/downloads'),
            max_concurrent=int(os.getenv('DOWNLOAD_MAX_CONCURRENT', '5'))
        )

        self.running = False
        self.setup_signal_handlers()

        # Production configuration
        self.production_config = DownloadConfig(
            timeout=int(os.getenv('DOWNLOAD_TIMEOUT', '300')),
            max_retries=int(os.getenv('DOWNLOAD_MAX_RETRIES', '5')),
            retry_delay=int(os.getenv('DOWNLOAD_RETRY_DELAY', '10')),
            ignore_errors=os.getenv('DOWNLOAD_IGNORE_ERRORS', 'false').lower() == 'true',
            rate_limit_mbps=float(os.getenv('DOWNLOAD_RATE_LIMIT', '0')) or None,
            download_archive='/app/archive.txt',
            verify_download=True
        )

        self.dm.set_default_config(self.production_config)

        # Set up callbacks
        self.dm.set_progress_callback(self.on_progress)
        self.dm.set_completion_callback(self.on_completion)
        self.dm.set_error_callback(self.on_error)

    def setup_signal_handlers(self):
        """Set up graceful shutdown handlers"""
        signal.signal(signal.SIGTERM, self.shutdown_handler)
        signal.signal(signal.SIGINT, self.shutdown_handler)

    def shutdown_handler(self, signum, frame):
        """Handle shutdown signals gracefully"""
        logger.info(f"Received signal {signum}, shutting down gracefully...")
        self.shutdown()

    def start(self):
        """Start the download service"""
        logger.info("Starting download service...")

        self.running = True
        self.dm.start_queue()

        # Start monitoring thread
        monitor_thread = threading.Thread(target=self.monitor_loop, daemon=True)
        monitor_thread.start()

        logger.info("Download service started successfully")

        # Keep main thread alive
        try:
            while self.running:
                time.sleep(1)
        except KeyboardInterrupt:
            self.shutdown()

    def shutdown(self):
        """Shutdown the service gracefully"""
        logger.info("Shutting down download service...")

        self.running = False

        # Stop the download manager
        self.dm.stop_queue(wait=True, timeout=30)

        logger.info("Download service stopped")

    def monitor_loop(self):
        """Monitor service health and stats"""
        while self.running:
            try:
                status = self.dm.get_queue_status()

                # Log status every 5 minutes
                logger.info(f"Queue status - Active: {status['active']}, "
                          f"Queued: {status['queued']}, "
                          f"Completed: {status['completed']}, "
                          f"Failed: {status['failed']}")

                # Health checks
                self.perform_health_checks()

            except Exception as e:
                logger.error(f"Monitor error: {e}")

            time.sleep(300)  # 5 minutes

    def perform_health_checks(self):
        """Perform system health checks"""
        # Check disk space
        import shutil
        total, used, free = shutil.disk_usage('/app/downloads')
        free_percent = (free / total) * 100

        if free_percent < 10:
            logger.warning(f"Low disk space: {free_percent:.1f}% free")

        # Check memory usage
        import psutil
        memory_percent = psutil.virtual_memory().percent

        if memory_percent > 80:
            logger.warning(f"High memory usage: {memory_percent:.1f}%")

    def on_progress(self, task_id, progress):
        """Log download progress"""
        if progress.percent % 25 == 0:  # Log every 25%
            logger.info(f"Download {task_id}: {progress.percent:.1f}% complete")

    def on_completion(self, task_id, result):
        """Log download completion"""
        logger.info(f"Download completed: {task_id} -> {result.local_path}")

    def on_error(self, task_id, error):
        """Log download errors"""
        logger.error(f"Download failed: {task_id} - {error}")

if __name__ == "__main__":
    service = DownloadService()
    service.start()
```

### Kubernetes Deployment

```yaml
# k8s-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: xlibrary-download-manager
spec:
  replicas: 3
  selector:
    matchLabels:
      app: xlibrary-download-manager
  template:
    metadata:
      labels:
        app: xlibrary-download-manager
    spec:
      containers:
      - name: download-manager
        image: xlibrary/download-manager:1.0.0
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        env:
        - name: DOWNLOAD_OUTPUT_DIR
          value: "/data/downloads"
        - name: DOWNLOAD_MAX_CONCURRENT
          value: "3"
        - name: DOWNLOAD_RATE_LIMIT
          value: "50"  # 50 Mbps limit
        volumeMounts:
        - name: download-storage
          mountPath: /data/downloads
        - name: queue-storage
          mountPath: /app/queue
      volumes:
      - name: download-storage
        persistentVolumeClaim:
          claimName: download-pvc
      - name: queue-storage
        persistentVolumeClaim:
          claimName: queue-pvc

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: download-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Ti

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: queue-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
```

**This comprehensive guide covers all major features of the Download Manager. You're now equipped to handle any downloading scenario from simple one-offs to production-scale systems!** 📥

---

## Next Steps

- **[Chapter 4: Files Manager](04.01%20Chapter%204%20-%20Files%20Manager%20-%20Design%20-%20Overview.md)** - Advanced file operations
- **[Chapter 5: Media Manager](05.01%20Chapter%205%20-%20Media%20Manager%20-%20Design%20-%20Overview.md)** - Video/image processing
- **[Chapter 0: Introduction](00.00%20Chapter%200%20-%20Introduction.md)** - Library overview and architecture