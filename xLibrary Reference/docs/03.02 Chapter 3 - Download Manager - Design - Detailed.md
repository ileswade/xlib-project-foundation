# Chapter 3: Download Manager - Detailed Design Discussion

> **ðŸ—ï¸ DEEP ARCHITECTURAL ANALYSIS**
> Comprehensive exploration of Download Manager's fallback strategies, queue management, concurrent processing, and multi-source download architecture.

## Table of Contents

- [Core Architecture](#core-architecture)
- [5-Tier Fallback System](#5-tier-fallback-system)
- [Queue Management System](#queue-management-system)
- [Strategy Selection Engine](#strategy-selection-engine)
- [Progress Tracking Architecture](#progress-tracking-architecture)
- [Concurrent Processing System](#concurrent-processing-system)
- [Source Detection and Handling](#source-detection-and-handling)
- [Error Recovery Mechanisms](#error-recovery-mechanisms)
- [Performance Optimization](#performance-optimization)
- [Extensibility Framework](#extensibility-framework)

---

## Core Architecture

### Component Overview

The Download Manager follows a layered architecture with sophisticated strategy management:

```
DownloadManager (Public Interface)
â”œâ”€â”€ Queue Management Layer
â”‚   â”œâ”€â”€ TaskQueue (Priority queue with persistence)
â”‚   â”œâ”€â”€ TaskManager (Task lifecycle management)
â”‚   â”œâ”€â”€ QueuePersistence (JSON-based state storage)
â”‚   â””â”€â”€ RecoveryManager (Restart and resume handling)
â”œâ”€â”€ Strategy Selection Layer
â”‚   â”œâ”€â”€ StrategyManager (Fallback coordination)
â”‚   â”œâ”€â”€ SourceDetector (URL pattern matching)
â”‚   â”œâ”€â”€ CapabilityMatcher (Feature requirement matching)
â”‚   â””â”€â”€ MethodSelector (Optimal strategy selection)
â”œâ”€â”€ Download Execution Layer
â”‚   â”œâ”€â”€ MediaDownloader (yt-dlp/youtube-dl)
â”‚   â”œâ”€â”€ HTTPDownloader (Direct HTTP/HTTPS)
â”‚   â”œâ”€â”€ SystemDownloader (wget/curl)
â”‚   â”œâ”€â”€ StreamDownloader (Live stream capture)
â”‚   â””â”€â”€ BatchDownloader (Parallel processing)
â”œâ”€â”€ Progress and Monitoring
â”‚   â”œâ”€â”€ ProgressTracker (Real-time progress)
â”‚   â”œâ”€â”€ CallbackManager (Event notifications)
â”‚   â”œâ”€â”€ StatisticsCollector (Performance metrics)
â”‚   â””â”€â”€ HealthMonitor (Resource usage tracking)
â”œâ”€â”€ Post-Processing Layer
â”‚   â”œâ”€â”€ ResultProcessor (File handling)
â”‚   â”œâ”€â”€ MetadataExtractor (Content information)
â”‚   â”œâ”€â”€ FormatConverter (Transcoding)
â”‚   â””â”€â”€ FileOrganizer (Output management)
â””â”€â”€ Configuration System
    â”œâ”€â”€ DownloadConfig (Per-download settings)
    â”œâ”€â”€ GlobalSettings (Manager-wide configuration)
    â”œâ”€â”€ StrategyConfig (Method-specific settings)
    â””â”€â”€ EnvironmentDetector (System capability detection)
```

### Design Patterns Used

#### 1. **Strategy Pattern**
Multiple download strategies with unified interface:

```python
class DownloadStrategy(ABC):
    """Abstract base for download strategies"""

    @abstractmethod
    def can_handle(self, url: str, config: DownloadConfig) -> bool:
        """Check if strategy can handle this download"""
        pass

    @abstractmethod
    def download(self, url: str, config: DownloadConfig) -> DownloadResult:
        """Execute download using this strategy"""
        pass

    @abstractmethod
    def get_capabilities(self) -> Dict[str, Any]:
        """Return strategy capabilities"""
        pass

class YtDlpStrategy(DownloadStrategy):
    """yt-dlp download strategy"""

    def can_handle(self, url: str, config: DownloadConfig) -> bool:
        return self._is_supported_site(url) and self._ytdlp_available()

    def download(self, url: str, config: DownloadConfig) -> DownloadResult:
        # yt-dlp specific implementation
        pass

class HTTPStrategy(DownloadStrategy):
    """Direct HTTP download strategy"""

    def can_handle(self, url: str, config: DownloadConfig) -> bool:
        return url.startswith(('http://', 'https://'))

    def download(self, url: str, config: DownloadConfig) -> DownloadResult:
        # HTTP-specific implementation with resume support
        pass
```

#### 2. **Chain of Responsibility Pattern**
Fallback chain with automatic strategy progression:

```python
class StrategyChain:
    """Manages fallback chain execution"""

    def __init__(self):
        self.strategies = []
        self.fallback_delays = [0, 1, 2, 5, 10]  # Exponential backoff

    def add_strategy(self, strategy: DownloadStrategy, priority: int = 0):
        """Add strategy to chain with priority"""
        self.strategies.append((priority, strategy))
        self.strategies.sort(key=lambda x: x[0])

    def execute(self, url: str, config: DownloadConfig) -> DownloadResult:
        """Execute strategies in fallback order"""
        errors = []

        for i, (_, strategy) in enumerate(self.strategies):
            if not strategy.can_handle(url, config):
                continue

            try:
                # Apply fallback delay
                if i > 0:
                    time.sleep(self.fallback_delays[min(i, len(self.fallback_delays) - 1)])

                result = strategy.download(url, config)
                if result.success:
                    return result
                else:
                    errors.append((strategy.__class__.__name__, result.error))

            except Exception as e:
                errors.append((strategy.__class__.__name__, str(e)))

        # All strategies failed
        return DownloadResult(
            success=False,
            errors=errors,
            attempted_strategies=[s.__class__.__name__ for _, s in self.strategies]
        )
```

#### 3. **Observer Pattern**
Progress and event notification system:

```python
class ProgressNotifier:
    """Notifies observers of download progress"""

    def __init__(self):
        self.observers = []

    def attach(self, observer: ProgressObserver):
        self.observers.append(observer)

    def notify_progress(self, task_id: str, progress: DownloadProgress):
        for observer in self.observers:
            observer.on_progress_update(task_id, progress)

    def notify_completion(self, task_id: str, result: DownloadResult):
        for observer in self.observers:
            observer.on_download_complete(task_id, result)

    def notify_error(self, task_id: str, error: Exception):
        for observer in self.observers:
            observer.on_download_error(task_id, error)
```

#### 4. **Command Pattern**
Download tasks as executable commands with undo/redo capability:

```python
class DownloadCommand:
    """Encapsulates a download operation"""

    def __init__(self, url: str, config: DownloadConfig, output_path: Path):
        self.url = url
        self.config = config
        self.output_path = output_path
        self.executed = False
        self.result = None

    def execute(self) -> DownloadResult:
        """Execute the download command"""
        if self.executed:
            raise RuntimeError("Command already executed")

        # Implementation
        self.result = self._perform_download()
        self.executed = True
        return self.result

    def undo(self):
        """Undo the download (cleanup files)"""
        if not self.executed or not self.result or not self.result.success:
            return

        # Cleanup downloaded files
        if self.result.local_path and Path(self.result.local_path).exists():
            Path(self.result.local_path).unlink()

        self.executed = False
        self.result = None
```

---

## 5-Tier Fallback System

### Fallback Strategy Architecture

The 5-tier fallback system provides bulletproof reliability:

```python
class FallbackManager:
    """Manages the 5-tier fallback system"""

    def __init__(self):
        self.tiers = [
            (1, YtDlpStrategy()),      # Primary: yt-dlp
            (2, YoutubeDlStrategy()),  # Secondary: youtube-dl
            (3, HTTPStrategy()),       # Tertiary: direct HTTP
            (4, WgetStrategy()),       # Quaternary: system wget
            (5, CurlStrategy())        # Final: system curl
        ]
        self.tier_timeouts = [30, 60, 120, 180, 300]  # Progressive timeouts

    def download_with_fallback(self, url: str, config: DownloadConfig) -> DownloadResult:
        """Execute download through fallback tiers"""
        attempt_results = []

        for tier, strategy in self.tiers:
            if not strategy.can_handle(url, config):
                continue

            # Configure tier-specific settings
            tier_config = self._adapt_config_for_tier(config, tier)
            tier_config.timeout = self.tier_timeouts[tier - 1]

            try:
                logger.info(f"Attempting download with {strategy.__class__.__name__} (Tier {tier})")

                result = strategy.download(url, tier_config)

                if result.success:
                    logger.info(f"Download successful with {strategy.__class__.__name__}")
                    result.strategy_used = strategy.__class__.__name__
                    result.tier_used = tier
                    result.fallback_attempts = attempt_results
                    return result
                else:
                    attempt_results.append({
                        'strategy': strategy.__class__.__name__,
                        'tier': tier,
                        'error': result.error,
                        'duration': result.duration
                    })

            except Exception as e:
                attempt_results.append({
                    'strategy': strategy.__class__.__name__,
                    'tier': tier,
                    'error': str(e),
                    'exception_type': type(e).__name__
                })

        # All tiers failed
        return DownloadResult(
            success=False,
            error="All fallback strategies failed",
            fallback_attempts=attempt_results
        )
```

### Strategy Implementation Details

#### Tier 1: yt-dlp Strategy
```python
class YtDlpStrategy(DownloadStrategy):
    """Primary strategy using yt-dlp"""

    def __init__(self):
        self.ytdlp = self._get_ytdlp_instance()
        self.supported_extractors = self._get_supported_extractors()

    def can_handle(self, url: str, config: DownloadConfig) -> bool:
        """Check if yt-dlp can handle this URL"""
        if not self._is_ytdlp_available():
            return False

        # Check against known extractors
        for extractor in self.supported_extractors:
            if extractor.suitable(url):
                return True

        return False

    def download(self, url: str, config: DownloadConfig) -> DownloadResult:
        """Execute download with yt-dlp"""
        ytdl_opts = self._build_ytdlp_options(config)

        # Progress hook
        def progress_hook(d):
            if d['status'] == 'downloading':
                self._update_progress(d)
            elif d['status'] == 'finished':
                self._handle_completion(d)

        ytdl_opts['progress_hooks'] = [progress_hook]

        try:
            with yt_dlp.YoutubeDL(ytdl_opts) as ydl:
                info = ydl.extract_info(url, download=True)
                return self._process_ytdlp_result(info)

        except Exception as e:
            return DownloadResult(
                success=False,
                error=f"yt-dlp failed: {str(e)}",
                strategy='yt-dlp'
            )

    def _build_ytdlp_options(self, config: DownloadConfig) -> Dict[str, Any]:
        """Build yt-dlp options from download config"""
        opts = {
            'outtmpl': str(config.output_path / '%(title)s.%(ext)s'),
            'format': self._get_format_string(config),
            'writeinfojson': config.write_info_json,
            'writesubtitles': config.embed_subtitles,
            'writeautomaticsub': config.auto_subtitles,
            'ignoreerrors': config.ignore_errors,
        }

        if config.audio_only:
            opts.update({
                'format': 'bestaudio/best',
                'postprocessors': [{
                    'key': 'FFmpegExtractAudio',
                    'preferredcodec': config.audio_codec or 'mp3',
                    'preferredquality': config.audio_quality or '192',
                }]
            })

        return opts
```

#### Tier 3: HTTP Strategy
```python
class HTTPStrategy(DownloadStrategy):
    """Direct HTTP download with resume support"""

    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'xlibrary-download-manager/1.0.0'
        })

    def download(self, url: str, config: DownloadConfig) -> DownloadResult:
        """Execute HTTP download with resume support"""
        try:
            # Get file info
            head_response = self.session.head(url, timeout=config.timeout)
            file_size = int(head_response.headers.get('content-length', 0))

            # Determine output filename
            output_path = self._determine_output_path(url, config, head_response)

            # Check for partial file (resume support)
            resume_pos = 0
            if output_path.exists() and head_response.headers.get('accept-ranges') == 'bytes':
                resume_pos = output_path.stat().st_size
                if resume_pos >= file_size:
                    # File already complete
                    return DownloadResult(
                        success=True,
                        local_path=str(output_path),
                        file_size=file_size,
                        strategy='HTTP'
                    )

            # Set up resume headers
            headers = {}
            if resume_pos > 0:
                headers['Range'] = f'bytes={resume_pos}-'

            # Download with streaming and progress
            response = self.session.get(
                url,
                headers=headers,
                stream=True,
                timeout=config.timeout
            )
            response.raise_for_status()

            return self._stream_download(response, output_path, resume_pos, file_size, config)

        except Exception as e:
            return DownloadResult(
                success=False,
                error=f"HTTP download failed: {str(e)}",
                strategy='HTTP'
            )

    def _stream_download(self, response, output_path, resume_pos, file_size, config):
        """Stream download with progress tracking"""
        mode = 'ab' if resume_pos > 0 else 'wb'
        downloaded = resume_pos
        chunk_size = 8192

        start_time = time.time()

        try:
            with open(output_path, mode) as f:
                for chunk in response.iter_content(chunk_size=chunk_size):
                    if chunk:
                        f.write(chunk)
                        downloaded += len(chunk)

                        # Update progress
                        if file_size > 0:
                            progress = DownloadProgress(
                                bytes_downloaded=downloaded,
                                total_bytes=file_size,
                                percent=downloaded / file_size * 100,
                                download_speed=self._calculate_speed(downloaded - resume_pos, start_time),
                                eta=self._calculate_eta(downloaded, file_size, start_time)
                            )
                            self._notify_progress(progress)

            return DownloadResult(
                success=True,
                local_path=str(output_path),
                file_size=downloaded,
                strategy='HTTP',
                resumed_from=resume_pos if resume_pos > 0 else None
            )

        except Exception as e:
            return DownloadResult(
                success=False,
                error=f"Streaming failed: {str(e)}",
                strategy='HTTP'
            )
```

---

## Queue Management System

### Persistent Queue Architecture

Enterprise-grade queue management with full persistence:

```python
class PersistentQueue:
    """Persistent download queue with JSON storage"""

    def __init__(self, queue_file: Path):
        self.queue_file = queue_file
        self.tasks: Dict[str, DownloadTask] = {}
        self.queue_lock = threading.RLock()
        self._load_queue()

    def add_task(self, task: DownloadTask) -> str:
        """Add task to persistent queue"""
        with self.queue_lock:
            task_id = task.task_id or str(uuid.uuid4())
            task.task_id = task_id
            task.created_at = datetime.now()
            task.status = DownloadStatus.QUEUED

            self.tasks[task_id] = task
            self._save_queue()

            return task_id

    def get_next_task(self) -> Optional[DownloadTask]:
        """Get next task from queue based on priority"""
        with self.queue_lock:
            # Get queued tasks sorted by priority and creation time
            queued_tasks = [
                task for task in self.tasks.values()
                if task.status == DownloadStatus.QUEUED
            ]

            if not queued_tasks:
                return None

            # Sort by priority (higher first), then by creation time (older first)
            queued_tasks.sort(key=lambda t: (-t.priority, t.created_at))

            next_task = queued_tasks[0]
            next_task.status = DownloadStatus.DOWNLOADING
            next_task.started_at = datetime.now()

            self._save_queue()
            return next_task

    def update_task_status(self, task_id: str, status: DownloadStatus, result: DownloadResult = None):
        """Update task status and save to disk"""
        with self.queue_lock:
            if task_id in self.tasks:
                task = self.tasks[task_id]
                task.status = status
                task.updated_at = datetime.now()

                if status == DownloadStatus.COMPLETED:
                    task.completed_at = datetime.now()
                    task.result = result
                elif status == DownloadStatus.FAILED:
                    task.failed_at = datetime.now()
                    task.result = result
                    task.retry_count += 1

                self._save_queue()

    def _save_queue(self):
        """Save queue state to JSON file"""
        try:
            queue_data = {
                'version': '1.0',
                'saved_at': datetime.now().isoformat(),
                'tasks': {
                    task_id: task.to_dict()
                    for task_id, task in self.tasks.items()
                }
            }

            # Atomic write
            temp_file = self.queue_file.with_suffix('.tmp')
            with open(temp_file, 'w') as f:
                json.dump(queue_data, f, indent=2)

            temp_file.replace(self.queue_file)

        except Exception as e:
            logger.error(f"Failed to save queue: {e}")

    def _load_queue(self):
        """Load queue state from JSON file"""
        if not self.queue_file.exists():
            return

        try:
            with open(self.queue_file) as f:
                queue_data = json.load(f)

            tasks_data = queue_data.get('tasks', {})
            for task_id, task_data in tasks_data.items():
                task = DownloadTask.from_dict(task_data)
                task.task_id = task_id
                self.tasks[task_id] = task

                # Reset running tasks to queued on startup
                if task.status == DownloadStatus.DOWNLOADING:
                    task.status = DownloadStatus.QUEUED

            logger.info(f"Loaded {len(self.tasks)} tasks from queue")

        except Exception as e:
            logger.error(f"Failed to load queue: {e}")
            # Create backup of corrupted file
            backup_file = self.queue_file.with_suffix('.backup')
            self.queue_file.rename(backup_file)
```

### Queue Processing Engine

Multi-threaded queue processor with resource management:

```python
class QueueProcessor:
    """Processes download queue with concurrent execution"""

    def __init__(self, download_manager: 'DownloadManager'):
        self.download_manager = download_manager
        self.executor = ThreadPoolExecutor(max_workers=download_manager.max_concurrent)
        self.running = False
        self.processor_thread = None
        self.active_downloads: Dict[str, Future] = {}

    def start(self):
        """Start queue processing"""
        if self.running:
            return

        self.running = True
        self.processor_thread = threading.Thread(target=self._process_queue, daemon=True)
        self.processor_thread.start()

    def stop(self):
        """Stop queue processing and wait for completion"""
        self.running = False

        if self.processor_thread:
            self.processor_thread.join(timeout=30)

        # Wait for active downloads to complete or cancel them
        for task_id, future in self.active_downloads.items():
            if not future.done():
                future.cancel()

        self.executor.shutdown(wait=True)

    def _process_queue(self):
        """Main queue processing loop"""
        while self.running:
            try:
                # Clean up completed downloads
                self._cleanup_completed_downloads()

                # Check if we have capacity for more downloads
                if len(self.active_downloads) >= self.download_manager.max_concurrent:
                    time.sleep(1)
                    continue

                # Get next task
                task = self.download_manager.queue.get_next_task()
                if not task:
                    time.sleep(1)
                    continue

                # Submit download
                future = self.executor.submit(self._execute_download, task)
                self.active_downloads[task.task_id] = future

            except Exception as e:
                logger.error(f"Queue processing error: {e}")
                time.sleep(1)

    def _execute_download(self, task: DownloadTask) -> DownloadResult:
        """Execute individual download task"""
        try:
            # Notify start
            self.download_manager._notify_download_started(task)

            # Execute download
            result = self.download_manager.strategy_manager.download(
                task.url,
                task.config
            )

            # Update task status
            if result.success:
                self.download_manager.queue.update_task_status(
                    task.task_id,
                    DownloadStatus.COMPLETED,
                    result
                )
                self.download_manager._notify_download_completed(task, result)
            else:
                # Check if we should retry
                if task.retry_count < task.config.max_retries:
                    # Requeue for retry
                    task.status = DownloadStatus.QUEUED
                    self.download_manager.queue.update_task_status(
                        task.task_id,
                        DownloadStatus.QUEUED
                    )
                else:
                    # Mark as failed
                    self.download_manager.queue.update_task_status(
                        task.task_id,
                        DownloadStatus.FAILED,
                        result
                    )
                    self.download_manager._notify_download_failed(task, result)

            return result

        except Exception as e:
            result = DownloadResult(
                success=False,
                error=str(e),
                strategy='unknown'
            )

            self.download_manager.queue.update_task_status(
                task.task_id,
                DownloadStatus.FAILED,
                result
            )
            self.download_manager._notify_download_error(task, e)

            return result

    def _cleanup_completed_downloads(self):
        """Remove completed downloads from active tracking"""
        completed_tasks = [
            task_id for task_id, future in self.active_downloads.items()
            if future.done()
        ]

        for task_id in completed_tasks:
            del self.active_downloads[task_id]
```

---

## Performance Optimization

### Concurrent Download Management

Intelligent resource allocation and bandwidth management:

```python
class ResourceManager:
    """Manages system resources for optimal download performance"""

    def __init__(self, max_concurrent: int):
        self.max_concurrent = max_concurrent
        self.active_downloads = {}
        self.bandwidth_limiter = BandwidthLimiter()
        self.resource_monitor = ResourceMonitor()

    def acquire_slot(self, task_id: str, estimated_size: int = 0) -> bool:
        """Acquire download slot with resource checking"""
        if len(self.active_downloads) >= self.max_concurrent:
            return False

        # Check system resources
        if not self._has_sufficient_resources(estimated_size):
            return False

        # Acquire bandwidth allocation
        bandwidth_allocation = self.bandwidth_limiter.allocate(task_id, estimated_size)

        self.active_downloads[task_id] = {
            'start_time': time.time(),
            'estimated_size': estimated_size,
            'bandwidth_allocation': bandwidth_allocation
        }

        return True

    def release_slot(self, task_id: str):
        """Release download slot and resources"""
        if task_id in self.active_downloads:
            # Release bandwidth allocation
            self.bandwidth_limiter.release(task_id)
            del self.active_downloads[task_id]

    def _has_sufficient_resources(self, estimated_size: int) -> bool:
        """Check if system has sufficient resources"""
        # Check available disk space
        if estimated_size > 0:
            available_space = self.resource_monitor.get_available_disk_space()
            if estimated_size > available_space * 0.9:  # Leave 10% buffer
                return False

        # Check memory usage
        memory_usage = self.resource_monitor.get_memory_usage()
        if memory_usage > 0.8:  # Limit at 80% memory usage
            return False

        # Check network connectivity
        if not self.resource_monitor.has_network_connectivity():
            return False

        return True

class BandwidthLimiter:
    """Manages bandwidth allocation across concurrent downloads"""

    def __init__(self, max_bandwidth_mbps: Optional[float] = None):
        self.max_bandwidth = max_bandwidth_mbps * 1024 * 1024 if max_bandwidth_mbps else None
        self.allocations = {}
        self.lock = threading.Lock()

    def allocate(self, task_id: str, estimated_size: int) -> Dict[str, Any]:
        """Allocate bandwidth for download"""
        with self.lock:
            if not self.max_bandwidth:
                return {'unlimited': True}

            active_count = len(self.allocations)
            if active_count == 0:
                bandwidth_per_download = self.max_bandwidth
            else:
                bandwidth_per_download = self.max_bandwidth / (active_count + 1)

            allocation = {
                'max_bytes_per_second': bandwidth_per_download,
                'allocated_at': time.time()
            }

            self.allocations[task_id] = allocation
            return allocation

    def release(self, task_id: str):
        """Release bandwidth allocation"""
        with self.lock:
            self.allocations.pop(task_id, None)
```

### Caching and Optimization

Smart caching system for improved performance:

```python
class DownloadCache:
    """Caches download results and metadata"""

    def __init__(self, cache_dir: Path, max_cache_size_mb: int = 1000):
        self.cache_dir = cache_dir
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.max_cache_size = max_cache_size_mb * 1024 * 1024
        self.metadata_cache = {}
        self.load_metadata_cache()

    def get_cached_result(self, url: str, config_hash: str) -> Optional[DownloadResult]:
        """Get cached download result if available"""
        cache_key = self._generate_cache_key(url, config_hash)

        if cache_key in self.metadata_cache:
            metadata = self.metadata_cache[cache_key]
            cached_file = self.cache_dir / metadata['filename']

            if cached_file.exists() and self._is_cache_valid(metadata):
                return DownloadResult(
                    success=True,
                    local_path=str(cached_file),
                    cached=True,
                    cache_hit_time=time.time()
                )

        return None

    def cache_result(self, url: str, config_hash: str, result: DownloadResult):
        """Cache successful download result"""
        if not result.success or not result.local_path:
            return

        cache_key = self._generate_cache_key(url, config_hash)
        source_path = Path(result.local_path)
        cached_filename = f"{cache_key}_{source_path.name}"
        cached_path = self.cache_dir / cached_filename

        try:
            # Copy file to cache
            shutil.copy2(source_path, cached_path)

            # Store metadata
            self.metadata_cache[cache_key] = {
                'url': url,
                'config_hash': config_hash,
                'filename': cached_filename,
                'cached_at': time.time(),
                'file_size': cached_path.stat().st_size,
                'source_path': str(source_path)
            }

            self.save_metadata_cache()
            self._cleanup_old_cache()

        except Exception as e:
            logger.warning(f"Failed to cache result: {e}")

    def _cleanup_old_cache(self):
        """Remove old cache entries to stay within size limit"""
        total_size = sum(
            Path(self.cache_dir / meta['filename']).stat().st_size
            for meta in self.metadata_cache.values()
            if Path(self.cache_dir / meta['filename']).exists()
        )

        if total_size <= self.max_cache_size:
            return

        # Sort by access time (oldest first)
        sorted_items = sorted(
            self.metadata_cache.items(),
            key=lambda x: x[1]['cached_at']
        )

        for cache_key, metadata in sorted_items:
            if total_size <= self.max_cache_size * 0.8:  # Remove until 80% of limit
                break

            cached_file = self.cache_dir / metadata['filename']
            if cached_file.exists():
                file_size = cached_file.stat().st_size
                cached_file.unlink()
                total_size -= file_size

            del self.metadata_cache[cache_key]

        self.save_metadata_cache()
```

---

**The Download Manager represents a sophisticated balance of reliability, performance, and usability - providing enterprise-grade downloading capabilities while maintaining simplicity for basic use cases.** ðŸ“¥

---

## Next Steps

- **[User Guide Overview](03.03%20Chapter%203%20-%20Download%20Manager%20-%20User%20Guide%20-%20Overview.md)** - Practical quick-start guide
- **[User Guide Detailed](03.04%20Chapter%203%20-%20Download%20Manager%20-%20User%20Guide%20-%20Detailed.md)** - Comprehensive feature documentation
- **[Chapter 4: Files Manager](04.01%20Chapter%204%20-%20Files%20Manager%20-%20Design%20-%20Overview.md)** - Advanced file operations